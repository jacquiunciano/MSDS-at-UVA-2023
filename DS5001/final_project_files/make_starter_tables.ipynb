{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de1b2b3-cfbf-4c28-9e0f-681ea182b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4dd3386-e479-4840-b7c7-fbea6d46e28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacqu\\OneDrive\\Documents\\MSDS-at-UVA-2023\\DS5001\\final_project_files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cd = os.getcwd()\n",
    "print(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93bc3277-03e6-4afa-8d8f-99227c840ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.read(\"../final_project_files/env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "390cc6f8-9dd0-4c0a-83d8-0eb471bcfa75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\jacqu\\\\OneDrive\\\\Documents\\\\MSDS-at-UVA-2023\\\\DS5001\\\\final_project_files\\\\data',\n",
       " 'C:\\\\Users\\\\jacqu\\\\OneDrive\\\\Documents\\\\MSDS-at-UVA-2023\\\\DS5001\\\\final_project_files\\\\output')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_home, output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a884e673-a9de-449e-931b-749a903cca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686ece9d-e820-4e2c-9d1a-d6d06b9bc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files = glob(f\"{data_home}/*/*\", recursive=True)\n",
    "# glob(\"/Users/*/data/*.txt\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11c653b-e377-4b73-b95c-76253394d983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'ASOIAF', 'Dragon_Chronicles', 'Warrior_Cats']\n"
     ]
    }
   ],
   "source": [
    "series_label = os.listdir(data_home)\n",
    "print(series_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924b1ed9-7a99-40f6-ac0e-828419dbc2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8dc2ea-ebe7-46ef-adab-3c79ccab1beb",
   "metadata": {},
   "source": [
    "### ASOIAF: A Game of Thrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5381dbb3-74a3-420c-821d-91e97e5cb6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacqu\\OneDrive\\Documents\\MSDS-at-UVA-2023\\DS5001\\final_project_files\\data\\ASOIAF\\01_a_game_of_thrones.txt\n"
     ]
    }
   ],
   "source": [
    "print(txt_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "067f1ea4-b328-40cc-b944-e843dae4ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASOIAF\n"
     ]
    }
   ],
   "source": [
    "print(txt_files[0].split('\\\\')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1683c411-8057-4224-96f6-f8d5b4f8aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eba71ff-502a-45f9-94d7-1906f4b26290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#books = pd.DataFrame()\n",
    "#for each_doc in txt_files[:3]:\n",
    "lines = open(txt_files[0], 'r', encoding='utf-8').readlines()\n",
    "text = pd.DataFrame(lines)\n",
    "text.columns = ['line_str']\n",
    "text.index.name = 'line_num'\n",
    "text.line_str = text.line_str.str.strip()\n",
    "text = text[~text.line_str.str.contains(r\"Table of Contents\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.iloc[135:145])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "822af688-499f-4b48-8f6b-b1f155d1bf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          line_str\n",
      "line_num          \n",
      "147       PROLOGUE\n",
      "                 line_str\n",
      "line_num                 \n",
      "49196     HOUSE BARATHEON\n"
     ]
    }
   ],
   "source": [
    "clip_pats = [\n",
    "    r\"^\\s*PROLOGUE\\s*$\",\n",
    "    r\"^\\s*HOUSE BARATHEON\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "print(text.loc[pat_a])\n",
    "print(text.loc[pat_b])\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[0]\n",
    "line_b = text.loc[pat_b].index[0] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58c1e8d7-72a9-4fd6-9008-8f5f68caf2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.loc[line_a : line_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da5a3469-2a5b-414e-bb98-ce79f3a05f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa58611e-1323-4c9b-9d1c-f370c632a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b0b21c1-fb32-4055-9975-c61356910439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36809d57-4f05-48ff-a494-54b9b6dc4212",
   "metadata": {},
   "outputs": [],
   "source": [
    "chap_pat = r\"^\\s*[A-Z]+\\s*$\"\n",
    "chap_lines = text.line_str.str.match(chap_pat, case=False)\n",
    "# text.loc[chap_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6908c34-c7c4-4c4d-9654-a236cb6216d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "833e896a-2ae3-4039-a484-3ccdbaef7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.chap_num = text.chap_num.ffill()\n",
    "# text.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50fa3ccf-734e-4146-bd0d-e84637e2d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "953d3f3c-ef46-43af-8516-51b52d30e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO = ['series','book_title','chap_num', 'para_num', 'sent_num', 'token_num'] #index names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8249456-2a22-457d-8c76-10a4cde31861",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e7b51f5-474d-47e9-9cca-2b5ca22d2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_pat = r'\\n \\n+'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[0].split('\\\\')[-1].split('.txt')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83e33bc1-3aba-415c-8dc8-86e64aff84b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "116ca5ff-8ba2-413f-ba85-ba245cd815af",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9337a504-2017-4742-8187-2e1f407a0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENTS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27d4889c-ec12-42a1-bc40-e78b030d7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a4172a5-6c0e-44d3-9c8a-312065956127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">01_a_game_of_thrones</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>We</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>should</td>\n",
       "      <td>should</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>start</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          token_str term_str\n",
       "book_title           chap_num para_num sent_num token_num                   \n",
       "01_a_game_of_thrones 1        0        1        1                We       we\n",
       "                                                2            should   should\n",
       "                                                3             start    start\n",
       "                                                4              back     back\n",
       "                                                5                 ,         "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2c9b21f-84d0-45a8-97cd-7b1e2e9699e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "asoiaf_1 = TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9eae6891-51df-46c6-861b-49433a9a2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f665eac-04c4-4fd3-ab83-837387553f2b",
   "metadata": {},
   "source": [
    "### ASOIAF: A Clash of Kings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6435495-9f84-4f32-a2d2-3fca5ec6d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#books = pd.DataFrame()\n",
    "#for each_doc in txt_files[:3]:\n",
    "lines = open(txt_files[1], 'r', encoding='utf-8').readlines()\n",
    "text = pd.DataFrame(lines)\n",
    "text.columns = ['line_str']\n",
    "text.index.name = 'line_num'\n",
    "text.line_str = text.line_str.str.strip()\n",
    "# text = text[~text.line_str.str.contains(r\"Table of Contents\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.sample(10))\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*PROLOGUE\\s*$\",\n",
    "    r\"^\\s*APPENDIX—THE KINGS AND THEIR COURTS\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b])\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[0]\n",
    "line_b = text.loc[pat_b].index[0] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "pattern = r'\\b([1-9]|[1-9][0-9]|([1-5][0-9]{2})|600)\\b'\n",
    "def replace_thing(text):\n",
    "    return re.sub(pattern, \"\", text)\n",
    "text.line_str = text.line_str.apply(replace_thing)\n",
    "# text.loc[32506]\n",
    "\n",
    "chap_pat = r\"^\\s*(PROLOGUE|CHAPTER)\\s*\"\n",
    "chap_lines = text.line_str.str.match(chap_pat, case=False)\n",
    "# text.loc[chap_lines]\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26fab5d7-306b-4f32-8346-cb230cd68ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "pattern = r\"\\n \\n+\"\n",
    "CHAPS.chap_str = CHAPS.chap_str.apply(replace_thing)\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[1].split('\\\\')[-1].split('.txt')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)\n",
    "PARAS.iloc[3:9]\n",
    "\n",
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "# SENTS.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74205e51-64af-459e-9931-aa70603d7099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">02_a_clash_of_kings</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comet</td>\n",
       "      <td>comet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>’</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tail</td>\n",
       "      <td>tail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         token_str term_str\n",
       "book_title          chap_num para_num sent_num token_num                   \n",
       "02_a_clash_of_kings 1        0        1        1               The      the\n",
       "                                               2             comet    comet\n",
       "                                               3                 ’         \n",
       "                                               4                 s        s\n",
       "                                               5              tail     tail"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1493f2c-b5fd-4bc1-bcdc-ee6dd19797c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "asoiaf_2 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c7ad7-29d5-4a8c-aa16-34bfc1224e3c",
   "metadata": {},
   "source": [
    "### ASOIAF: A Storm of Swords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15ed8fc8-443d-48eb-9931-6ea38e605518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#books = pd.DataFrame()\n",
    "#for each_doc in txt_files[:3]:\n",
    "lines = open(txt_files[2], 'r', encoding='utf-8').readlines()\n",
    "text = pd.DataFrame(lines)\n",
    "text.columns = ['line_str']\n",
    "text.index.name = 'line_num'\n",
    "text.line_str = text.line_str.str.strip()\n",
    "# text = text[~text.line_str.str.match(r\"\\n\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.sample(10))\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*PROLOGUE\\s*$\",\n",
    "    r\"^\\s*Appendix\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b])\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[0]\n",
    "line_b = text.loc[pat_b].index[0] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^\\s*([A-Z]+|Epilogue)\\s*$\"\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines]\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d40e1431-a2c1-4721-b413-602d12a36f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[2].split('\\\\')[-1].split('.txt')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)\n",
    "\n",
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "#SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f426cdc-f8fb-473a-9064-9895edcd328f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">03_a_storm_of_swords</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>was</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grey</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          token_str term_str\n",
       "book_title           chap_num para_num sent_num token_num                   \n",
       "03_a_storm_of_swords 1        0        1        1               The      the\n",
       "                                                2               day      day\n",
       "                                                3               was      was\n",
       "                                                4              grey     grey\n",
       "                                                5               and      and"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b72f7e29-4729-41b1-ad70-6611bbb969c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "asoiaf_3 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58835656-4e18-4f51-b2b7-34f2df0db85f",
   "metadata": {},
   "source": [
    "### ASOIAF: A Feast for Crows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e83b1ff1-4086-4360-932c-1d7bb8223ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(txt_files[3], 'r', encoding='utf-8').readlines()\n",
    "text = pd.DataFrame(lines)\n",
    "text.columns = ['line_str']\n",
    "text.index.name = 'line_num'\n",
    "# text.line_str = text.line_str.str.strip()\n",
    "# text = text[~text.line_str.str.match(r\"\\n\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70492b85-7c66-4255-b6ca-373faed09231",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_pats = [\n",
    "    r\"^\\s*PROLOGUE\\s*$\",\n",
    "    r\"^\\s*MEANWHILE, BACK ON THE WALL...\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b])\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[0]\n",
    "line_b = text.loc[pat_b].index[0] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^\\s*([A-Z\\s]+|THE KRAKEN’S DAUGHTER)$\"\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines].shape\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "LINES['line_str'] = LINES.line_str.str.replace(r\"\\”\\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1358a443-db5d-4029-b6e3-06e014e689b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\n+'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[3].split('\\\\')[-1].split('.txt')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)\n",
    "\n",
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "# SENTS.sample(2)\n",
    "# SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb9c942d-aea3-4451-9b91-7d88e49eb76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">04_a_feast_for_crows</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>“</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dragons</td>\n",
       "      <td>dragons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>”</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          token_str term_str\n",
       "book_title           chap_num para_num sent_num token_num                   \n",
       "04_a_feast_for_crows 1        0        1        1                 “         \n",
       "                                                2           Dragons  dragons\n",
       "                                                3                 ,         \n",
       "                                                4                 ”         \n",
       "                                                5              said     said"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1685b714-eed5-4af9-b676-cef09447ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "asoiaf_4 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1b5cdb-7a2c-44e3-9f17-84fe4d40ecc5",
   "metadata": {},
   "source": [
    "### ASOIAF: A Dance with Dragons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07342aab-cad1-444f-8e56-60c3aeff3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(txt_files[4], 'r', encoding='utf-8').readlines()\n",
    "text = pd.DataFrame(lines)\n",
    "text.columns = ['line_str']\n",
    "text.index.name = 'line_num'\n",
    "# text.line_str = text.line_str.str.strip()\n",
    "# text = text[~text.line_str.str.match(r\"\\n\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abe2c064-9dd5-473c-9064-28570091bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_pats = [\n",
    "    r\"^\\s*PROLOGUE\\s*$\",\n",
    "    r\"^\\s*WESTEROS\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b])\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[0]\n",
    "line_b = text.loc[pat_b].index[0] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^\\s*([A-Z ]+|THE QUEEN’S HAND|EPILOGUE|THE MERCHANT’S MAN)$\"\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines].shape\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "LINES['line_str'] = LINES.line_str.str.replace(r\"\\”\\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5fd05ae4-9795-4ef1-836c-7fa460e44534",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\n+'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[4].split('\\\\')[-1].split('.txt')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)\n",
    "\n",
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "# SENTS.sample(2)\n",
    "# SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a6fb917-18dd-4be3-8923-304409603a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">05_a_dance_with_dragons</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>night</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>was</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rank</td>\n",
       "      <td>rank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             token_str  \\\n",
       "book_title              chap_num para_num sent_num token_num             \n",
       "05_a_dance_with_dragons 1        0        1        1               The   \n",
       "                                                   2             night   \n",
       "                                                   3               was   \n",
       "                                                   4              rank   \n",
       "                                                   5              with   \n",
       "\n",
       "                                                             term_str  \n",
       "book_title              chap_num para_num sent_num token_num           \n",
       "05_a_dance_with_dragons 1        0        1        1              the  \n",
       "                                                   2            night  \n",
       "                                                   3              was  \n",
       "                                                   4             rank  \n",
       "                                                   5             with  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc021a56-6b00-4c0a-a078-e0af6329bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "asoiaf_5 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a0ae7-8d5f-4c3e-b39d-3347ddb11be7",
   "metadata": {},
   "source": [
    "### Warrior Cats: Into the Wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8201ec99-d5bf-422c-a8ac-ab6ce714c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e1d9f98-a480-430c-b6f7-4d681745f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    # Open the provided PDF file\n",
    "    document = fitz.open(pdf_path)\n",
    "\n",
    "    # Initialize a list to hold each line of text\n",
    "    lines = []\n",
    "\n",
    "    # Loop through each page in the PDF\n",
    "    for page in document:\n",
    "        # Extract text from the page as blocks\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "\n",
    "        # Each block is a tuple where the fourth element is the text\n",
    "        for block in blocks:\n",
    "            # Split the text in each block into lines\n",
    "            block_lines = block[4].split('\\n')\n",
    "\n",
    "            # Extend the lines list with the lines from this block\n",
    "            lines.extend(block_lines)\n",
    "\n",
    "    # Close the document\n",
    "    document.close()\n",
    "\n",
    "    # Create a DataFrame from the lines list\n",
    "    df = pd.DataFrame(lines, columns=['line_str'])\n",
    "    df.index.name = 'line_num'\n",
    "    # Return the DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82a83623-d8e5-464a-b4cc-dbc8a8bd9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[12])\n",
    "# text.line_str = text.line_str.str.strip()\n",
    "text = text[~text.line_str.str.contains(r\"PMWarriorsintotheWild\")]\n",
    "text = text[~text.line_str.str.contains(r\"6/26/2009\")]\n",
    "text = text[~text.line_str.str.contains(r\"file:///H:/E-Books/E\")]\n",
    "# text = text[~text.line_str.str.match(r\"\\n\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.head(10))\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*PROLOGUE\\s*$\",\n",
    "    r\"^\\s*About the Author\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b].tail(1))\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^\\s*(PROLOGUE|CHAPTER)\\s*\\d*$\"\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f53998e-32d2-449f-a959-c3e3028c34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[12].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f4bfd72-2bd8-4239-89a9-4b32eeacca41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "SENTS.sent_str.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d55bc71f-b917-4162-80c0-a95a98dce2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">01_into_the_wild</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>half-moon</td>\n",
       "      <td>halfmoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glowed</td>\n",
       "      <td>glowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>smooth</td>\n",
       "      <td>smooth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       token_str  term_str\n",
       "book_title       chap_num para_num sent_num token_num                     \n",
       "01_into_the_wild 1        0        1        1                  A         a\n",
       "                                            2          half-moon  halfmoon\n",
       "                                            3             glowed    glowed\n",
       "                                            4                 on        on\n",
       "                                            5             smooth    smooth"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e715e770-757a-4ab3-b752-63a5a222bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_1 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4224e58d-64cc-448e-a2de-dd4315bef048",
   "metadata": {},
   "source": [
    "### Warrior Cats: Fire and Ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fe0dae4-cabb-40a0-8b2f-ddbd7c86dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[13])\n",
    "# text.line_str = text.line_str.str.strip()\n",
    "text = text[~text.line_str.str.contains(r\"WarriorsFireandIce\")]\n",
    "text = text[~text.line_str.str.contains(r\"6/26/2009\")]\n",
    "text = text[~text.line_str.str.contains(r\"file:///H:/E-Books/E\")]\n",
    "# text = text[~text.line_str.str.match(r\"\\n\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.head(10))\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*PROLOGUE\\s*$\",\n",
    "    r\"^\\s*About the Author\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b].tail(1))\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^\\s*(PROLOGUE|CHAPTER)\\s*\\d*$\"\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35dedf30-5ef1-4f3f-84c3-c4a5879584bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[13].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ecb0f9ba-abe3-4078-8eca-45092fda44d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "SENTS.sent_str.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e91cf529-0a60-44df-bac4-f01911d42e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">02_fire_and_ice</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Orange</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flames</td>\n",
       "      <td>flames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lapped</td>\n",
       "      <td>lapped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token_str term_str\n",
       "book_title      chap_num para_num sent_num token_num                   \n",
       "02_fire_and_ice 1        0        1        1            Orange   orange\n",
       "                                           2            flames   flames\n",
       "                                           3            lapped   lapped\n",
       "                                           4                at       at\n",
       "                                           5               the      the"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "066edaff-d976-4180-9375-b8101ea386db",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_2 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd180ac9-30ed-4fbb-aff4-9a2938badcd8",
   "metadata": {},
   "source": [
    "### Warrior Cats: Forest of Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5a965ee-7991-4361-9d55-a8dfd2c3be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[14])\n",
    "# text.line_str = text.line_str.str.strip()\n",
    "text = text[~text.line_str.str.contains(r\"WarriorsForestofSecrets\")]\n",
    "text = text[~text.line_str.str.contains(r\"6/26/2009\")]\n",
    "text = text[~text.line_str.str.contains(r\"file:///H:/E-Books/E\")]\n",
    "# text = text[~text.line_str.str.match(r\"\\n\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.head(10))\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*PROLOGUE\\s*$\",\n",
    "    r\"^\\s*About the Author\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b].tail(1))\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^\\s*(PROLOGUE|CHAPTER)\\s*\\d*$\"\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines].shape\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[14].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a7e8ec42-c345-48ca-8537-c569c1dc6746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">03_forest_of_secrets</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Cold</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gripped</td>\n",
       "      <td>gripped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forest</td>\n",
       "      <td>forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          token_str term_str\n",
       "book_title           chap_num para_num sent_num token_num                   \n",
       "03_forest_of_secrets 1        0        1        1              Cold     cold\n",
       "                                                2           gripped  gripped\n",
       "                                                3               the      the\n",
       "                                                4            forest   forest\n",
       "                                                5                 ,         "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()\n",
    "\n",
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cec68dd0-0d28-4118-b102-3c094003716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_3 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c1e9f-2d95-47de-9bc3-c30ba1fe9b33",
   "metadata": {},
   "source": [
    "### Warrior Cats: Rising Storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2e42cc2-0d62-4cdd-8307-fff192d46bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[15])\n",
    "# text.line_str = text.line_str.str.strip()\n",
    "text = text[~text.line_str.str.contains(r\"WarriorsRisingStorm\")]\n",
    "text = text[~text.line_str.str.contains(r\"6/26/2009\")]\n",
    "text = text[~text.line_str.str.contains(r\"file:///H:/E-Books/E\")]\n",
    "# text = text[~text.line_str.str.match(r\"\\n\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.head(10))\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*PROLOGUE\\s*$\",\n",
    "    r\"^\\s*About the Author\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b].tail(1))\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^\\s*(PROLOGUE|CHAPTER)\\s*\\d*$\"\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines].shape\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[15].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "123dc6a6-196d-478d-815e-097350b03d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">04_rising_storm</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>An</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agonized</td>\n",
       "      <td>agonized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>groan</td>\n",
       "      <td>groan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>echoed</td>\n",
       "      <td>echoed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>across</td>\n",
       "      <td>across</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token_str  term_str\n",
       "book_title      chap_num para_num sent_num token_num                    \n",
       "04_rising_storm 1        0        1        1                An        an\n",
       "                                           2          agonized  agonized\n",
       "                                           3             groan     groan\n",
       "                                           4            echoed    echoed\n",
       "                                           5            across    across"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()\n",
    "\n",
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "77aab6c7-e04f-4dc0-8875-51cecb9692ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_4 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59e5568-eac0-4864-a343-619eabb761dc",
   "metadata": {},
   "source": [
    "### Warrior Cats: A Dangerous Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3055cf1d-b498-4240-8bf7-1b0288605f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[16])\n",
    "# text.line_str = text.line_str.str.strip()\n",
    "text = text[~text.line_str.str.contains(r\"WarriorsaDangerousPath\")]\n",
    "text = text[~text.line_str.str.contains(r\"6/26/2009\")]\n",
    "text = text[~text.line_str.str.contains(r\"file:///H:/E-Books/E\")]\n",
    "# text = text[~text.line_str.str.match(r\"\\n\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.head(10))\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*PROLOGUE\\s*$\",\n",
    "    r\"^\\s*About the Author\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b].tail(1))\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^\\s*(PROLOGUE|CHAPTER)\\s*\\d*$\"\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines].shape\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[16].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5d1ef807-3811-423e-8363-0a2973ae3b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">05_a_dangerous_path</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Inside</td>\n",
       "      <td>inside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kennel-that-moves</td>\n",
       "      <td>kennelthatmoves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>everything</td>\n",
       "      <td>everything</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  token_str  \\\n",
       "book_title          chap_num para_num sent_num token_num                      \n",
       "05_a_dangerous_path 1        0        1        1                     Inside   \n",
       "                                               2                        the   \n",
       "                                               3          kennel-that-moves   \n",
       "                                               4                          ,   \n",
       "                                               5                 everything   \n",
       "\n",
       "                                                                 term_str  \n",
       "book_title          chap_num para_num sent_num token_num                   \n",
       "05_a_dangerous_path 1        0        1        1                   inside  \n",
       "                                               2                      the  \n",
       "                                               3          kennelthatmoves  \n",
       "                                               4                           \n",
       "                                               5               everything  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()\n",
    "\n",
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5443e0f-1e26-4aac-9c1c-2fc71c46d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_5 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b4064f-ab80-4a50-9a3f-0c0cd6266bb6",
   "metadata": {},
   "source": [
    "### Warrior Cats: The Darkest Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c04e147-c855-479a-b7fc-5fcfbdd8adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[17])\n",
    "# text.line_str = text.line_str.str.strip()\n",
    "text = text[~text.line_str.str.contains(r\"WarriorstheDarkestHour\")]\n",
    "text = text[~text.line_str.str.contains(r\"6/26/2009\")]\n",
    "text = text[~text.line_str.str.contains(r\"file:///H:/E-Books/E\")]\n",
    "# text = text[~text.line_str.str.match(r\"\\n\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.head(10))\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*PROLOGUE\\s*$\",\n",
    "    r\"^\\s*About the Author\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b].tail(1))\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^\\s*(PROLOGUE|CHAPTER)\\s*\\d*$\"\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines].shape\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[17].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8db86097-87de-48ff-aeb3-6f20201cb433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">06_the_darkest_hour</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Rain</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fell</td>\n",
       "      <td>fell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>steadily</td>\n",
       "      <td>steadily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>drumming</td>\n",
       "      <td>drumming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         token_str  term_str\n",
       "book_title          chap_num para_num sent_num token_num                    \n",
       "06_the_darkest_hour 1        0        1        1              Rain      rain\n",
       "                                               2              fell      fell\n",
       "                                               3          steadily  steadily\n",
       "                                               4                 ,          \n",
       "                                               5          drumming  drumming"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()\n",
    "\n",
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc294d06-262f-4858-9b82-2ebf12501af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_6 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f78f98-c14f-4081-abe6-18720e01a23d",
   "metadata": {},
   "source": [
    "### Dragon Chronicles: The Fire Within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d85f0d00-3ffa-4681-921d-0f900a764a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[5])\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "text['line_str'].replace(' ', '\\n', inplace=True)\n",
    "text = text[~text.line_str.str.contains(r\"THE FIRE WITHIN\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART TWO\")]\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# print(text.head(10))\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*WELCOME TO WAYWARD CRESCENT\\s*$\",\n",
    "    r\"^\\s*ABOUT THE AUTHOR\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a].index[-1])\n",
    "# print(text.loc[pat_b].index[-1])\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^[A-Z\\!\\\"\\’ \\.\\,\\-\\‘]+$\"\n",
    "a_list = [\"DRAGONS’ DEN\", \"WELCOME TO SCRUBBLEY LIBRARY GARDENS\", \"SAFETY\", \"DO NOT ENTER\", \"KILNING IN PROGRESS\"]\n",
    "pattern = '|'.join([re.escape(word) for word in a_list])\n",
    "text.line_str = text.line_str.apply(replace_thing)\n",
    "#pattern = r\" \"\n",
    "#text.line_str = text.line_str.apply(replace_thing)\n",
    "text.loc[8033, 'line_str'] = text.loc[8033, 'line_str'].replace(\" \", \"\\n\")\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# chap_lines\n",
    "# text.loc[chap_lines].shape\n",
    "# [\"DRAGONS’ DEN\", \"WELCOME TO SCRUBBLEY LIBRARY GARDENS\", \"SAFETY\", \"DO NOT ENTER\", \"KILNING IN PROGRESS\"]\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[5].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddec29fc-02bb-453a-afea-284b0330e559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">01_the_fire_within</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Well</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>here</td>\n",
       "      <td>here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>are</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        token_str term_str\n",
       "book_title         chap_num para_num sent_num token_num                   \n",
       "01_the_fire_within 1        0        1        1              Well     well\n",
       "                                              2                 ,         \n",
       "                                              3              here     here\n",
       "                                              4                we       we\n",
       "                                              5               are      are"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()\n",
    "\n",
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a1bc1e5a-fe6f-442f-a6b1-9bb7ffdceabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_1 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11490ff-d609-4019-96ef-20ff90aac3e9",
   "metadata": {},
   "source": [
    "### Dragon Chronicles: Icefire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e0d5741-5fbe-4bdd-8992-0624a77f9b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[6])\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "text['line_str'].replace(' ', '\\n', inplace=True)\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# text.head(10)\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*THE WISHING DRAGON\\s*$\",\n",
    "    r\"^\\s*ABOUT THE AUTHOR\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b])\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^[A-Z\\!\\\"\\’ \\.\\,\\-\\‘]+$\"\n",
    "# a_list = [\"DRAGONS’ DEN\", \"WELCOME TO SCRUBBLEY LIBRARY GARDENS\", \"SAFETY\", \"DO NOT ENTER\", \"KILNING IN PROGRESS\"]\n",
    "# pattern = '|'.join([re.escape(word) for word in a_list])\n",
    "# text.line_str = text.line_str.apply(replace_thing)\n",
    "#pattern = r\" \"\n",
    "#text.line_str = text.line_str.apply(replace_thing)\n",
    "# text.loc[8033, 'line_str'] = text.loc[8033, 'line_str'].replace(\" \", \"\\n\")\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines]\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[6].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7830cb1d-79eb-419c-9111-6ad7a12651b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">02_icefire</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>David</td>\n",
       "      <td>david</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if</td>\n",
       "      <td>if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your</td>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>face</td>\n",
       "      <td>face</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                token_str term_str\n",
       "book_title chap_num para_num sent_num token_num                   \n",
       "02_icefire 1        0        1        1             David    david\n",
       "                                      2                 ,         \n",
       "                                      3                if       if\n",
       "                                      4              your     your\n",
       "                                      5              face     face"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()\n",
    "\n",
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "011c149b-77e9-411d-b46e-ff37e223d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_2 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb53e1f-16dd-4463-95ad-79268554e7f4",
   "metadata": {},
   "source": [
    "### Dragon Chronicles: The Fire Eternal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd736d98-7ac3-461a-b72d-48da32ffd652",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[7])\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "text['line_str'].replace(' ', '\\n', inplace=True)\n",
    "text = text[~text.line_str.str.contains(r\"Part Two\")]\n",
    "text = text[~text.line_str.str.contains(r\"Part Three\")]\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# text.head(10)\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*ARCTIC ICE CAP, UNRECORDED TIME\\s*$\",\n",
    "    r\"^\\s*About the Author\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b])\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^([A-Z\\!\\\"\\’ \\.\\,\\-\\‘]+|Epilogue)$\"\n",
    "a_list = [\"SVALBARD ARCHIPELAGO, UNRECORDED TIME\", \n",
    "          \"THE ISLAND ONCE CALLED THE TOOTH OF RAGNAR\", \n",
    "          \"GODDESS, SEDNA\", \n",
    "          \"KILNING IN PROGRESS\"]\n",
    "pattern = '|'.join([re.escape(word) for word in a_list])\n",
    "text.line_str = text.line_str.apply(replace_thing)\n",
    "#pattern = r\" \"\n",
    "#text.line_str = text.line_str.apply(replace_thing)\n",
    "text.loc[2488, 'line_str'] = text.loc[2488, 'line_str'].replace(\"A\", \"a\")\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines]\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[7].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b20cccdf-3d64-4889-8a46-746d2bb51c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">03_the_fire_eternal</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>It</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>began</td>\n",
       "      <td>began</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wind</td>\n",
       "      <td>wind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         token_str term_str\n",
       "book_title          chap_num para_num sent_num token_num                   \n",
       "03_the_fire_eternal 1        0        1        1                It       it\n",
       "                                               2             began    began\n",
       "                                               3              with     with\n",
       "                                               4                 a        a\n",
       "                                               5              wind     wind"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()\n",
    "\n",
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2430d3db-f85f-45aa-a370-f9587f29f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_3 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6561d26f-c327-4dd4-8a97-aa1ecfd93316",
   "metadata": {},
   "source": [
    "### Dragon Chronicles: Fire Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a80f42de-340a-4b07-a428-8ee3395c9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[8])\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "text['line_str'].replace(' ', '\\n', inplace=True)\n",
    "text = text[~text.line_str.str.contains(r\"PART TWO\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART THREE\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART FOUR\")]\n",
    "text = text[~text.line_str.str.contains(r\"EPILOGUE\")]\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# text.head(10)\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*1 THE SHOOTING\\s*$\",\n",
    "    r\"^\\s*Acknowledgments\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b])\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] - 1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^[0-9]+ [A-Z0-9\\!\\\"\\’ \\.\\,\\--\\‘\\…]+$\"\n",
    "a_list = [\"42 Wayward Crescent, Scrubbley.\", \n",
    "          \"42 Wayward Crescent,\"]\n",
    "pattern = '|'.join([re.escape(word) for word in a_list])\n",
    "text.line_str = text.line_str.apply(replace_thing)\n",
    "#pattern = r\" \"\n",
    "#text.line_str = text.line_str.apply(replace_thing)\n",
    "#text.loc[2488, 'line_str'] = text.loc[2488, 'line_str'].replace(\"A\", \"a\")\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines].shape\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[8].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a019b944-7ac1-4366-a068-39c42ccdb4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">04_fire_star</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Boom</td>\n",
       "      <td>boom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>Boom</td>\n",
       "      <td>boom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <td>Boom</td>\n",
       "      <td>boom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  token_str term_str\n",
       "book_title   chap_num para_num sent_num token_num                   \n",
       "04_fire_star 1        0        1        1              Boom     boom\n",
       "                                        2                 .         \n",
       "                               2        1              Boom     boom\n",
       "                                        2                 .         \n",
       "                               3        1              Boom     boom"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()\n",
    "\n",
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b408007a-0122-4ee7-9a11-89f6365abe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_4 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced83578-aa87-4542-b514-5ff47fc03a1d",
   "metadata": {},
   "source": [
    "### Dragon Chronicles: Dark Fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c346c917-d45c-458e-bc2e-1ab65cadacf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[9])\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "text['line_str'].replace(' ', '\\n', inplace=True)\n",
    "text = text[~text.line_str.str.contains(r\"PART TWO\")]\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# text.head(10)\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*1 LUCY’S JOURNAL\\s*$\",\n",
    "    r\"^\\s*Sometimes\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b])\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] \n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^[0-9]+ [A-Z0-9\\!\\\"\\’ \\.\\,\\--\\‘\\…]+$\"\n",
    "#a_list = [\"42 Wayward Crescent, Scrubbley.\", \n",
    "#          \"42 Wayward Crescent,\"]\n",
    "#pattern = '|'.join([re.escape(word) for word in a_list])\n",
    "#text.line_str = text.line_str.apply(replace_thing)\n",
    "#pattern = r\" \"\n",
    "#text.line_str = text.line_str.apply(replace_thing)\n",
    "#text.loc[2488, 'line_str'] = text.loc[2488, 'line_str'].replace(\"A\", \"a\")\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines]\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[9].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bdfb2128-e0ae-45c6-8d22-760463990884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">05_dark_fire</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>OK</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weird</td>\n",
       "      <td>weird</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  token_str term_str\n",
       "book_title   chap_num para_num sent_num token_num                   \n",
       "05_dark_fire 1        0        1        1                OK       ok\n",
       "                                        2                 ,         \n",
       "                                        3              this     this\n",
       "                                        4                is       is\n",
       "                                        5             weird    weird"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()\n",
    "\n",
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c1204fb6-9254-4299-be10-027f8b9be93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_5 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa82c09c-dd21-4019-bcee-3dff60f3b6c8",
   "metadata": {},
   "source": [
    "### Dragon Chronicles: Fire World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e4e55efd-5756-4cfc-803c-e890b14f507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(txt_files[10])\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "text['line_str'].replace(' ', '\\n', inplace=True)\n",
    "text = text[~text.line_str.str.contains(r\"PART TWO\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART THREE\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART FOUR\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART FIVE\")]\n",
    "# text.dropna(subset=['line_str'], inplace=True)\n",
    "# text.head(10)\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*PART ONE\\s*$\",\n",
    "    r\"^\\s*About the Author\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b])\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]\n",
    "line_b = text.loc[pat_b].index[-1] \n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^[0-9]+\\.\\s*$\"\n",
    "#a_list = [\"42 Wayward Crescent, Scrubbley.\", \n",
    "#          \"42 Wayward Crescent,\"]\n",
    "#pattern = '|'.join([re.escape(word) for word in a_list])\n",
    "#text.line_str = text.line_str.apply(replace_thing)\n",
    "#pattern = r\" \"\n",
    "#text.line_str = text.line_str.apply(replace_thing)\n",
    "#text.loc[2488, 'line_str'] = text.loc[2488, 'line_str'].replace(\"A\", \"a\")\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines]\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[10].split('\\\\')[-1].split('.pdf')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "541a2f9e-7b96-421a-91f5-38956c92d724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">06_fire_world</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Professor</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Merriman</td>\n",
       "      <td>merriman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>Eliza</td>\n",
       "      <td>eliza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    token_str   term_str\n",
       "book_title    chap_num para_num sent_num token_num                      \n",
       "06_fire_world 1        0        1        1          Professor  professor\n",
       "                                         2           Merriman   merriman\n",
       "                                         3                  .           \n",
       "                                2        1              Eliza      eliza\n",
       "                                         2                  .           "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()\n",
    "\n",
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "588913f0-ddd7-4d98-8930-363c8d1450bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_6 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d08847-b0b2-4325-abc6-469737993a62",
   "metadata": {},
   "source": [
    "### Dragon Chronicles: The Fire Ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e454f471-c7e9-4f7e-8d7f-fe2c692be529",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(txt_files[11], 'r', encoding='utf-8').readlines()\n",
    "text = pd.DataFrame(lines)\n",
    "text.columns = ['line_str']\n",
    "text.index.name = 'line_num'\n",
    "text.line_str = text.line_str.str.strip()\n",
    "text = text[~text.line_str.str.contains(r\"PART ONE\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART TWO\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART THREE\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART FOUR\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART FIVE\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART SIX\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART SEVEN\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART EIGHT\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART NINE\")]\n",
    "text = text[~text.line_str.str.contains(r\"PART TEN\")]\n",
    "text['line_str'].replace('', '\\n', inplace=True)\n",
    "\n",
    "clip_pats = [\n",
    "    r\"^\\s*Voss\\s*$\",\n",
    "    r\"^\\s*THE END\\s*$\"\n",
    "]\n",
    "# finding where the pattern is\n",
    "pat_a = text.line_str.str.match(clip_pats[0])\n",
    "pat_b = text.line_str.str.match(clip_pats[1])\n",
    "# print(text.loc[pat_a])\n",
    "# print(text.loc[pat_b])\n",
    "\n",
    "# finding the line where the pattern is\n",
    "line_a = text.loc[pat_a].index[-1]-1\n",
    "line_b = text.loc[pat_b].index[-1]-1\n",
    "# text._get_value(line_a, 'line_str'), text._get_value(line_b+1, 'line_str')\n",
    "\n",
    "text = text.loc[line_a : line_b]\n",
    "# text.sample(10)\n",
    "\n",
    "chap_pat = r\"^([0-9]*\\. [A-Z0-9:\\!\\’ \\.\\,\\‘]+|Voss|[A-Z0-9\\!\\’ \\.\\,\\‘]+)$\"\n",
    "a_list = [\"REGION, UNRECORDED TIME\", \n",
    "          \"SCRUBBLEY\",\n",
    "         \"OF GWILANNA\",\n",
    "         \"LISTENING DRAGON\",\n",
    "         \"OF A LIBRARY GARDEN\",\n",
    "         \"GWILANNA\",\n",
    "         \"DARKLINGS\"]\n",
    "pattern = '|'.join([re.escape(word) for word in a_list])\n",
    "text.line_str = text.line_str.apply(replace_thing)\n",
    "#pattern = r\" \"\n",
    "#text.line_str = text.line_str.apply(replace_thing)\n",
    "text.loc[4498, 'line_str'] = text.loc[4498, 'line_str'].replace(\"1\", \"one\")\n",
    "text.loc[8251, 'line_str'] = text.loc[8251, 'line_str'].replace(\"42.\", \"forty-two\")\n",
    "text.loc[11044, 'line_str'] = text.loc[11044, 'line_str'].replace(\"HRRR!\", \"hrrr!\")\n",
    "chap_lines = text.line_str.str.match(chap_pat)\n",
    "# text.loc[chap_lines]\n",
    "\n",
    "text.loc[chap_lines, 'chap_num'] = [i+1 for i in range(text.loc[chap_lines].shape[0])]\n",
    "# text.loc[chap_lines].head()\n",
    "\n",
    "text.chap_num = text.chap_num.ffill()\n",
    "LINES = text.dropna(subset=['chap_num'])\n",
    "LINES = LINES.loc[~chap_lines]\n",
    "LINES.chap_num = LINES.chap_num.astype('int')\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\.\\n\", \".\\n\\n\\n\", regex=True)\n",
    "# LINES['line_str'] = LINES.line_str.str.replace(r\"\\” \\n\", \"\\\"\\n\\n\\n\", regex=True)\n",
    "# LINES.head(10)\n",
    "\n",
    "CHAPS = LINES.groupby(OHCO[2:3]).line_str.apply(lambda x: ' '.join(x))\\\n",
    "                                                .to_frame('chap_str')\n",
    "CHAPS.chap_str = CHAPS.chap_str.str.strip()\n",
    "# CHAPS.head(1)\n",
    "\n",
    "para_pat = r'\\n\\s'\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[2:4]\n",
    "# PARAS['para_str'] = PARAS.para_str.str.replace('\\n ', ' ')\n",
    "# PARAS['series'] = txt_files[0].split('\\\\')[-2]\n",
    "PARAS['book_title'] = txt_files[11].split('\\\\')[-1].split('.txt')[0]\n",
    "PARAS = PARAS.reset_index().set_index(OHCO[1:4])\n",
    "# PARAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "89ebfd42-f9bb-4b0b-914b-1b5ec9c8e017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">07_the_fire_ascending</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boy</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           token_str term_str\n",
       "book_title            chap_num para_num sent_num token_num                   \n",
       "07_the_fire_ascending 1        0        1        1                 I        i\n",
       "                                                 2               was      was\n",
       "                                                 3                 a        a\n",
       "                                                 4               boy      boy\n",
       "                                                 5                of       of"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS = PARAS.para_str.apply(nltk.sent_tokenize).to_frame('sent_str').explode('sent_str').reset_index()\n",
    "SENTS['sent_num'] = SENTS.groupby(OHCO[1:4]).cumcount() + 1\n",
    "SENTS.set_index(OHCO[1:5], inplace=True)\n",
    "SENTS.sample(2)\n",
    "SENTS = SENTS[SENTS.sent_str.isna()==False]\n",
    "# SENTS.sent_str.isna().sum()\n",
    "\n",
    "TOKENS = SENTS.sent_str.apply(nltk.word_tokenize).to_frame('token_str').explode('token_str').reset_index()\n",
    "TOKENS['token_num'] = TOKENS.groupby(OHCO[1:5]).cumcount() + 1\n",
    "TOKENS.set_index(OHCO[1:6], inplace=True)\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4d256807-9066-4bc3-ab2e-502e37471e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_7 = TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680aa330-4b02-48a4-948f-14286e88ca97",
   "metadata": {},
   "source": [
    "### Making the CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "947d9342-a4e6-483d-a57a-b9c6bad2bbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>04_a_feast_for_crows</th>\n",
       "      <th>43</th>\n",
       "      <th>125</th>\n",
       "      <th>1</th>\n",
       "      <th>7</th>\n",
       "      <td>into</td>\n",
       "      <td>into</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_into_the_wild</th>\n",
       "      <th>17</th>\n",
       "      <th>76</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04_a_feast_for_crows</th>\n",
       "      <th>35</th>\n",
       "      <th>11</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03_a_storm_of_swords</th>\n",
       "      <th>67</th>\n",
       "      <th>151</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <td>Keep</td>\n",
       "      <td>keep</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_a_game_of_thrones</th>\n",
       "      <th>43</th>\n",
       "      <th>21</th>\n",
       "      <th>2</th>\n",
       "      <th>16</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04_a_feast_for_crows</th>\n",
       "      <th>46</th>\n",
       "      <th>37</th>\n",
       "      <th>4</th>\n",
       "      <th>18</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02_a_clash_of_kings</th>\n",
       "      <th>52</th>\n",
       "      <th>63</th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04_rising_storm</th>\n",
       "      <th>9</th>\n",
       "      <th>57</th>\n",
       "      <th>1</th>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02_a_clash_of_kings</th>\n",
       "      <th>67</th>\n",
       "      <th>48</th>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <td>what</td>\n",
       "      <td>what</td>\n",
       "      <td>WP</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_a_game_of_thrones</th>\n",
       "      <th>12</th>\n",
       "      <th>45</th>\n",
       "      <th>1</th>\n",
       "      <th>34</th>\n",
       "      <td>her</td>\n",
       "      <td>her</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          token_str term_str  \\\n",
       "book_title           chap_num para_num sent_num token_num                      \n",
       "04_a_feast_for_crows 43       125      1        7              into     into   \n",
       "01_into_the_wild     17       76       1        5               the      the   \n",
       "04_a_feast_for_crows 35       11       5        7               the      the   \n",
       "03_a_storm_of_swords 67       151      1        10             Keep     keep   \n",
       "01_a_game_of_thrones 43       21       2        16                a        a   \n",
       "04_a_feast_for_crows 46       37       4        18              the      the   \n",
       "02_a_clash_of_kings  52       63       1        6              from     from   \n",
       "04_rising_storm      9        57       1        12              for      for   \n",
       "02_a_clash_of_kings  67       48       2        2              what     what   \n",
       "01_a_game_of_thrones 12       45       1        34              her      her   \n",
       "\n",
       "                                                           pos pos_group  \n",
       "book_title           chap_num para_num sent_num token_num                 \n",
       "04_a_feast_for_crows 43       125      1        7           IN        IN  \n",
       "01_into_the_wild     17       76       1        5           DT        DT  \n",
       "04_a_feast_for_crows 35       11       5        7           DT        DT  \n",
       "03_a_storm_of_swords 67       151      1        10          NN        NN  \n",
       "01_a_game_of_thrones 43       21       2        16          DT        DT  \n",
       "04_a_feast_for_crows 46       37       4        18          DT        DT  \n",
       "02_a_clash_of_kings  52       63       1        6           IN        IN  \n",
       "04_rising_storm      9        57       1        12          IN        IN  \n",
       "02_a_clash_of_kings  67       48       2        2           WP        WP  \n",
       "01_a_game_of_thrones 12       45       1        34         PRP        PR  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS = pd.concat([asoiaf_1, asoiaf_2, asoiaf_3,\n",
    "                     asoiaf_4, asoiaf_5,\n",
    "                     wc_1, wc_2, wc_3, wc_4, wc_5, wc_6,\n",
    "                     dc_1, dc_2, dc_3, dc_4, dc_5, dc_6, dc_7], axis=0)\n",
    "CORPUS[\"pos\"] = [pos for (word, pos) in nltk.pos_tag(CORPUS.term_str)]\n",
    "CORPUS = CORPUS[CORPUS.term_str != '']\n",
    "CORPUS['pos_group'] = CORPUS.pos.str[:2]\n",
    "CORPUS.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d2fb24d3-8fca-4557-9719-b97ea5bd3cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2789558, 4)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a5b62-218a-4adc-a51a-4df3549c0f6d",
   "metadata": {},
   "source": [
    "### Making the LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c963f86-e85a-43f1-9376-9fcf9b2722e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series = {'ASOIAF':['01_a_game_of_thrones',\n",
    "                    '02_a_clash_of_kings',\n",
    "                    '03_a_storm_of_swords',\n",
    "                    '04_a_feast_for_crows',\n",
    "                    '05_a_dance_with_dragons'], \n",
    "           'Warrior_Cats':['the_lord_of_the_rings',\n",
    "                           '01_into_the_wild',\n",
    "                           '02_fire_and_ice',\n",
    "                           '03_forest_of_secrets',\n",
    "                           '04_rising_storm',\n",
    "                           '05_a_dangerous_path',\n",
    "                           '06_the_darkest_hour'],  \n",
    "           'Last_Dragon_Chronicles': ['01_the_fire_within',\n",
    "                                      '02_icefire',\n",
    "                                      '03_the_fire_eternal',\n",
    "                                      '04_fire_star',\n",
    "                                      '05_dark_fire',\n",
    "                                      '06_fire_world',\n",
    "                                      '07_the_fire_ascending']}\n",
    "\n",
    "authors = {'George R.R. Martin':['01_a_game_of_thrones',\n",
    "                    '02_a_clash_of_kings',\n",
    "                    '03_a_storm_of_swords',\n",
    "                    '04_a_feast_for_crows',\n",
    "                    '05_a_dance_with_dragons'], \n",
    "           'Kate Cary':['01_into_the_wild',\n",
    "                   '02_fire_and_ice',\n",
    "                   '04_rising_storm'],\n",
    "           'Cherith  Baldry':['03_forest_of_secrets', \n",
    "                      '05_a_dangerous_path',\n",
    "                      '06_the_darkest_hour'],  \n",
    "           'Chris D\\'Lacey': ['01_the_fire_within',\n",
    "                              '02_icefire',\n",
    "                              '03_the_fire_eternal',\n",
    "                              '04_fire_star',\n",
    "                              '05_dark_fire',\n",
    "                              '06_fire_world',\n",
    "                              '07_the_fire_ascending']}\n",
    "\n",
    "years = {'01_a_game_of_thrones': 1996,\n",
    "         '02_a_clash_of_kings': 1998,\n",
    "         '03_a_storm_of_swords': 2000,\n",
    "         '04_a_feast_for_crows': 2005,\n",
    "         '05_a_dance_with_dragons': 2001, \n",
    "         '01_into_the_wild': 2003,\n",
    "         '02_fire_and_ice': 2003,\n",
    "         '03_forest_of_secrets': 2003,\n",
    "         '04_rising_storm': 2004,\n",
    "         '05_a_dangerous_path': 2004,\n",
    "         '06_the_darkest_hour': 2004,\n",
    "         '01_the_fire_within': 2001,\n",
    "         '02_icefire': 2003,\n",
    "         '03_the_fire_eternal': 2005,\n",
    "         '04_fire_star': 2007,\n",
    "         '05_dark_fire': 2009,\n",
    "         '06_fire_world': 2011,\n",
    "         '07_the_fire_ascending': 2013}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1317890c-4690-40f8-bdf5-d09a3f93784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB = CORPUS.groupby(level=0).term_str.count().to_frame('book_length')\n",
    "LIB['n_chaps'] = CORPUS.reset_index()[['book_title','chap_num']]\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby('book_title').chap_num.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c9c8883a-c028-474f-bf0d-34c759aa4c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_length</th>\n",
       "      <th>n_chaps</th>\n",
       "      <th>series</th>\n",
       "      <th>year</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01_a_game_of_thrones</th>\n",
       "      <td>297169</td>\n",
       "      <td>73</td>\n",
       "      <td>ASOIAF</td>\n",
       "      <td>1996</td>\n",
       "      <td>George R.R. Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_into_the_wild</th>\n",
       "      <td>64386</td>\n",
       "      <td>26</td>\n",
       "      <td>Warrior_Cats</td>\n",
       "      <td>2003</td>\n",
       "      <td>Kate Cary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_the_fire_within</th>\n",
       "      <td>51223</td>\n",
       "      <td>42</td>\n",
       "      <td>Last_Dragon_Chronicles</td>\n",
       "      <td>2001</td>\n",
       "      <td>Chris D'Lacey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02_a_clash_of_kings</th>\n",
       "      <td>324987</td>\n",
       "      <td>70</td>\n",
       "      <td>ASOIAF</td>\n",
       "      <td>1998</td>\n",
       "      <td>George R.R. Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02_fire_and_ice</th>\n",
       "      <td>73544</td>\n",
       "      <td>31</td>\n",
       "      <td>Warrior_Cats</td>\n",
       "      <td>2003</td>\n",
       "      <td>Kate Cary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      book_length  n_chaps                  series  year  \\\n",
       "book_title                                                                 \n",
       "01_a_game_of_thrones       297169       73                  ASOIAF  1996   \n",
       "01_into_the_wild            64386       26            Warrior_Cats  2003   \n",
       "01_the_fire_within          51223       42  Last_Dragon_Chronicles  2001   \n",
       "02_a_clash_of_kings        324987       70                  ASOIAF  1998   \n",
       "02_fire_and_ice             73544       31            Warrior_Cats  2003   \n",
       "\n",
       "                                  author  \n",
       "book_title                                \n",
       "01_a_game_of_thrones  George R.R. Martin  \n",
       "01_into_the_wild               Kate Cary  \n",
       "01_the_fire_within         Chris D'Lacey  \n",
       "02_a_clash_of_kings   George R.R. Martin  \n",
       "02_fire_and_ice                Kate Cary  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop through each key-value pair in the dictionary\n",
    "for key, indices in series.items():\n",
    "    # print(key, indices)\n",
    "    mask = LIB.index.isin(indices)\n",
    "    # print(mask)\n",
    "    LIB.loc[mask, 'series'] = key\n",
    "    \n",
    "LIB['year'] = pd.NA\n",
    "for key, indices in years.items():\n",
    "    LIB.loc[key, 'year'] = indices\n",
    "\n",
    "for key, indices in authors.items():\n",
    "    # print(key, indices)\n",
    "    mask = LIB.index.isin(indices)\n",
    "    # print(mask)\n",
    "    LIB.loc[mask, 'author'] = key\n",
    "LIB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "baf9d69f-e889-4b5a-bb17-a9ffb5e1925a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154975.44444444444"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.book_length.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f908334-1758-4cbd-addc-ddf7a810b3b6",
   "metadata": {},
   "source": [
    "### Making the VOCAB"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36fb0322-e559-42e1-b1d9-9263a1eaeefc",
   "metadata": {},
   "source": [
    "VOCAB = CORPUS.term_str.value_counts().to_frame('n').sort_index()\n",
    "#VOCAB.index.name = 'term_str'\n",
    "# VOCAB['n_chars'] = VOCAB.index.str.len()\n",
    "VOCAB['p'] = VOCAB.n / VOCAB.n.sum()\n",
    "VOCAB['i'] = -np.log2(VOCAB.p)\n",
    "VOCAB['max_pos'] = CORPUS[['term_str','pos']].value_counts().unstack(fill_value=0).idxmax(1)\n",
    "TPM = CORPUS[['term_str','pos']].value_counts().unstack()\n",
    "VOCAB['n_pos'] = TPM.count(1)\n",
    "VOCAB['cat_pos'] = CORPUS[['term_str','pos']].value_counts().to_frame('n').reset_index()\\\n",
    "    .groupby(['term_str']).pos.apply(lambda x: set(x))\n",
    "VOCAB['max_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().unstack(fill_value=0).idxmax(1)\n",
    "# VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fd3e7b0f-6293-4cfc-9167-1bc1b247b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "363efe3c-685a-471f-ad6b-da9747ecb0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "982cfe14-e232-42ca-8758-5d044ab6abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_docs(CORPUS, ohco_level, term_col='term_str'):\n",
    "    OHCO = CORPUS.index.names\n",
    "    CORPUS[term_col] = CORPUS[term_col].astype('str')\n",
    "    DOC = CORPUS.groupby(OHCO[:ohco_level])[term_col].apply(lambda x:' '.join(x)).to_frame('doc_str')\n",
    "    return DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d45b2110-4c18-492e-974f-de566531edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC = gather_docs(CORPUS, 1)\n",
    "# DOC['n_tokens'] = DOC.doc_str.apply(lambda x: len(x.split()))\n",
    "\n",
    "tfidf_engine = TfidfVectorizer(\n",
    "    stop_words = 'english',\n",
    "    ngram_range = (1,3),\n",
    "    # max_features = n_terms,\n",
    "    norm = 'l2', \n",
    "    use_idf = True)\n",
    "\n",
    "X = tfidf_engine.fit_transform(DOC.doc_str)\n",
    "\n",
    "DTM = pd.DataFrame(X.toarray(), \n",
    "                   columns=tfidf_engine.get_feature_names_out(), \n",
    "                   index=DOC.index)\n",
    "\n",
    "TFIDF = pd.DataFrame(X.toarray(), \n",
    "                     columns=tfidf_engine.get_feature_names_out(), \n",
    "                     index=DTM.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "411f97bb-bec9-45e9-82d0-3579e052d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time  # Just for simulating a delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c1a82fc8-06c5-44bd-9664-6818e7090aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nltk_pos_tags(n_grams):\n",
    "    tags = {}\n",
    "    for n_gram in tqdm(n_grams, desc=\"Stemming n-grams\"):\n",
    "        tokens = nltk.word_tokenize(n_gram)  # Tokenize the n-gram\n",
    "        tagged = nltk.pos_tag(tokens)  # Get POS tags\n",
    "        # Joining tags to match your desired output format\n",
    "        tags[n_gram] = ' '.join([tag for _, tag in tagged])\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f7d38c53-a68f-4636-8125-1414400f0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_ngrams(n_grams):\n",
    "    stemmed_ngrams = []\n",
    "    for n_gram in tqdm(n_grams, desc=\"Stemming n-grams\"):\n",
    "        tokens = nltk.word_tokenize(n_gram)  # Tokenize the n-gram into individual words\n",
    "        stemmed_tokens = [stemmer.stem(token) for token in tokens]  # Stem each word\n",
    "        stemmed_ngram = ' '.join(stemmed_tokens)  # Rejoin the stemmed words into an n-gram\n",
    "        stemmed_ngrams.append(stemmed_ngram)\n",
    "    return stemmed_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7e85fd03-a608-4e95-83c2-0b21ada447b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = TFIDF[TFIDF > 0].count().to_frame('df')\n",
    "VOCAB.index.name = 'term_str'\n",
    "VOCAB['dfidf'] = VOCAB.df * np.log2(len(TFIDF)/VOCAB.df)\n",
    "VOCAB['df'].fillna(0, inplace=True)\n",
    "VOCAB['dfidf'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "03926bb3-72fc-4a6c-bf91-9bc04475b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['n'] = VOCAB.index.value_counts()\n",
    "VOCAB['p'] = VOCAB.n / VOCAB.n.sum()\n",
    "VOCAB['i'] = -np.log2(VOCAB.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "971353bb-5c2f-4ba1-bb86-961ae965de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(VOCAB.index)[:10]\n",
    "# get_nltk_pos_tags(test)\n",
    "# stem_ngrams(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a0989ebf-1fe1-4e65-a6f4-82d9dc85fca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stemming n-grams: 100%|████████████| 2086449/2086449 [32:13<00:00, 1078.91it/s]\n"
     ]
    }
   ],
   "source": [
    "VOCAB['pos_tag'] = get_nltk_pos_tags(list(VOCAB.index))\n",
    "VOCAB['max_pos'] = VOCAB.groupby(level=0)['pos_tag'].agg(lambda x: x.mode()[0])\n",
    "VOCAB['pos_group'] = VOCAB.max_pos.str[:2]\n",
    "VOCAB['max_pos_group'] = VOCAB.groupby(level=0)['pos_group'].value_counts().unstack(fill_value=0).idxmax(1)\n",
    "# VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a13d02ef-c351-476b-9103-47bcd85aefc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stemming n-grams: 100%|████████████| 2086449/2086449 [06:59<00:00, 4968.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>dfidf</th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>pos_group</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forests</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claws raked</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NNS VBD</td>\n",
       "      <td>NNS VBD</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>claw rake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lurked</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>lurk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wasn listening</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NN VBG</td>\n",
       "      <td>NN VBG</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>wasn listen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wasn long</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NN RB</td>\n",
       "      <td>NN RB</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>wasn long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodded slowly</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>VBN RB</td>\n",
       "      <td>VBN RB</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>nod slowli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kindled</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>kindl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exquisite</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>exquisit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think asked</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NN VBD</td>\n",
       "      <td>NN VBD</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>think ask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whispered ear</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>VBN NN</td>\n",
       "      <td>VBN NN</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>whisper ear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlaws</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>outlaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beetle</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>beetl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat thought</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NN VBD</td>\n",
       "      <td>NN VBD</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>cat thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borrowed</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>borrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did wish</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>VBD VB</td>\n",
       "      <td>VBD VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>did wish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dead eyes</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>JJ NNS</td>\n",
       "      <td>JJ NNS</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0</td>\n",
       "      <td>dead eye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expressionless</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>expressionless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>puckered</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>pucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say wanted</th>\n",
       "      <td>7</td>\n",
       "      <td>9.537991</td>\n",
       "      <td>1</td>\n",
       "      <td>4.792832e-07</td>\n",
       "      <td>20.992618</td>\n",
       "      <td>NN VBD</td>\n",
       "      <td>NN VBD</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>say want</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                df     dfidf  n             p          i  pos_tag  max_pos  \\\n",
       "term_str                                                                     \n",
       "effect           7  9.537991  1  4.792832e-07  20.992618       NN       NN   \n",
       "forests          7  9.537991  1  4.792832e-07  20.992618      NNS      NNS   \n",
       "claws raked      7  9.537991  1  4.792832e-07  20.992618  NNS VBD  NNS VBD   \n",
       "lurked           7  9.537991  1  4.792832e-07  20.992618      VBN      VBN   \n",
       "wasn listening   7  9.537991  1  4.792832e-07  20.992618   NN VBG   NN VBG   \n",
       "wasn long        7  9.537991  1  4.792832e-07  20.992618    NN RB    NN RB   \n",
       "nodded slowly    7  9.537991  1  4.792832e-07  20.992618   VBN RB   VBN RB   \n",
       "kindled          7  9.537991  1  4.792832e-07  20.992618      VBN      VBN   \n",
       "exquisite        7  9.537991  1  4.792832e-07  20.992618       NN       NN   \n",
       "think asked      7  9.537991  1  4.792832e-07  20.992618   NN VBD   NN VBD   \n",
       "whispered ear    7  9.537991  1  4.792832e-07  20.992618   VBN NN   VBN NN   \n",
       "outlaws          7  9.537991  1  4.792832e-07  20.992618      NNS      NNS   \n",
       "beetle           7  9.537991  1  4.792832e-07  20.992618       NN       NN   \n",
       "cat thought      7  9.537991  1  4.792832e-07  20.992618   NN VBD   NN VBD   \n",
       "borrowed         7  9.537991  1  4.792832e-07  20.992618      VBN      VBN   \n",
       "did wish         7  9.537991  1  4.792832e-07  20.992618   VBD VB   VBD VB   \n",
       "dead eyes        7  9.537991  1  4.792832e-07  20.992618   JJ NNS   JJ NNS   \n",
       "expressionless   7  9.537991  1  4.792832e-07  20.992618       NN       NN   \n",
       "puckered         7  9.537991  1  4.792832e-07  20.992618      VBN      VBN   \n",
       "say wanted       7  9.537991  1  4.792832e-07  20.992618   NN VBD   NN VBD   \n",
       "\n",
       "               pos_group max_pos_group  stop     stem_porter  \n",
       "term_str                                                      \n",
       "effect                NN            NN     0          effect  \n",
       "forests               NN            NN     0          forest  \n",
       "claws raked           NN            NN     0       claw rake  \n",
       "lurked                VB            VB     0            lurk  \n",
       "wasn listening        NN            NN     0     wasn listen  \n",
       "wasn long             NN            NN     0       wasn long  \n",
       "nodded slowly         VB            VB     0      nod slowli  \n",
       "kindled               VB            VB     0           kindl  \n",
       "exquisite             NN            NN     0        exquisit  \n",
       "think asked           NN            NN     0       think ask  \n",
       "whispered ear         VB            VB     0     whisper ear  \n",
       "outlaws               NN            NN     0          outlaw  \n",
       "beetle                NN            NN     0           beetl  \n",
       "cat thought           NN            NN     0     cat thought  \n",
       "borrowed              VB            VB     0          borrow  \n",
       "did wish              VB            VB     0        did wish  \n",
       "dead eyes             JJ            JJ     0        dead eye  \n",
       "expressionless        NN            NN     0  expressionless  \n",
       "puckered              VB            VB     0          pucker  \n",
       "say wanted            NN            NN     0        say want  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB['stop'] = VOCAB.index.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')\n",
    "\n",
    "VOCAB['stem_porter'] = stem_ngrams(list(VOCAB.index))\n",
    "\n",
    "# VOCAB[VOCAB.stop == 1].sample(5)\n",
    "\n",
    "VOCAB.sort_values('dfidf', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "45d00b04-53bc-42c0-968f-b1f29e914273",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS.to_csv(f\"{output_dir}\\\\CORPUS.csv\")\n",
    "LIB.to_csv(f\"{output_dir}\\\\LIB.csv\")\n",
    "# VOCAB.to_csv(f\"{output_dir}\\\\VOCAB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6e038909-9e7b-428d-894d-1473e0a7536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['ngram_length'] = VOCAB.index.str.split().str.len()\n",
    "VOCAB = VOCAB[VOCAB.ngram_length.isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4116b3f6-a730-4a31-aa25-f88182d955e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.ngram_length.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c2784ba4-ff13-402f-88e5-c98605e27a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.ngram_length = VOCAB.ngram_length.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b1152833-a3bf-4a6c-94b7-d847f2c41def",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20 = VOCAB.sort_values('dfidf', ascending=False).head(20)[[\"dfidf\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9d9e50d4-7bf0-4c17-a16c-4a0f5561462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.to_csv(f\"{output_dir}\\\\VOCAB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ba667313-7308-4fa5-a92b-f5c7bdad3002",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20.to_csv(f\"{output_dir}\\\\top_20_dfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "096e232b-260d-48db-9cfc-35eb08ef2231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forests</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claws raked</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lurked</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wasn listening</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wasn long</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodded slowly</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kindled</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exquisite</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think asked</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whispered ear</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlaws</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beetle</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat thought</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borrowed</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did wish</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dead eyes</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expressionless</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>puckered</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say wanted</th>\n",
       "      <td>9.537991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dfidf\n",
       "term_str                \n",
       "effect          9.537991\n",
       "forests         9.537991\n",
       "claws raked     9.537991\n",
       "lurked          9.537991\n",
       "wasn listening  9.537991\n",
       "wasn long       9.537991\n",
       "nodded slowly   9.537991\n",
       "kindled         9.537991\n",
       "exquisite       9.537991\n",
       "think asked     9.537991\n",
       "whispered ear   9.537991\n",
       "outlaws         9.537991\n",
       "beetle          9.537991\n",
       "cat thought     9.537991\n",
       "borrowed        9.537991\n",
       "did wish        9.537991\n",
       "dead eyes       9.537991\n",
       "expressionless  9.537991\n",
       "puckered        9.537991\n",
       "say wanted      9.537991"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
