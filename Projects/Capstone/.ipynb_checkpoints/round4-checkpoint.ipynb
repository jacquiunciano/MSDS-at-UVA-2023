{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ea0558-2f12-409c-a870-037a6606edfe",
   "metadata": {},
   "source": [
    "### Starting Point\n",
    "The following code blocks are what I've been developing for the past 3 rounds. I have the needed packages, the flag decomposer, and the get_styles() function that I've created and will keep and use to develop more functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b99967a9-4ec0-483e-8e03-55287559deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed packages\n",
    "import fitz\n",
    "import sys\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea6b048-b2eb-42cc-934c-58c08900d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flags_decomposer(flags):\n",
    "    \"\"\"Make font flags human readable.\"\"\"\n",
    "    l = []\n",
    "    if flags & 2 ** 0:\n",
    "        l.append(\"superscript\")\n",
    "    if flags & 2 ** 1:\n",
    "        l.append(\"italic\")\n",
    "    if flags & 2 ** 2:\n",
    "        l.append(\"serifed\")\n",
    "    else:\n",
    "        l.append(\"sans\")\n",
    "    if flags & 2 ** 3:\n",
    "        l.append(\"monospaced\")\n",
    "    else:\n",
    "        l.append(\"proportional\")\n",
    "    if flags & 2 ** 4:\n",
    "        l.append(\"bold\")\n",
    "    return \", \".join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17875de7-ebe5-4fad-b4da-393658af4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_styles(doc):\n",
    "    style_counts = []\n",
    "\n",
    "    for page in doc:\n",
    "        #, flags=11\n",
    "\n",
    "        paths = page.get_drawings()  # get drawings on the page\n",
    "\n",
    "        drawn_lines = []\n",
    "        for p in paths:\n",
    "            # print(p)\n",
    "            for item in p[\"items\"]:\n",
    "                # print(item[0])\n",
    "                if item[0] == \"l\":  # an actual line\n",
    "                    # print(item[1], item[2])\n",
    "                    p1, p2 = item[1], item[2]\n",
    "                    if p1.y == p2.y:\n",
    "                        drawn_lines.append((p1, p2))\n",
    "                elif item[0] == \"re\":  # a rectangle: check if height is small\n",
    "                    # print(item[0])\n",
    "                    # print(item[1])\n",
    "                    r = item[1]\n",
    "                    if r.width > r.height and r.height <= 2:\n",
    "                        drawn_lines.append((r.tl, r.tr))  # take top left / right points\n",
    "        \n",
    "        blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                    \n",
    "                    font_properties = \"Font: '%s' (%s), size %g, color #%06x\" % (\n",
    "                        s[\"font\"],  # font name\n",
    "                        flags_decomposer(s[\"flags\"]),  # readable font flags\n",
    "                        s[\"size\"],  # font size\n",
    "                        s[\"color\"],  # font color\n",
    "                    )\n",
    "\n",
    "                    r = fitz.Rect(s['bbox']) \n",
    "                    for p1, p2 in drawn_lines:  # check distances for start / end points\n",
    "                        if abs(r.bl - p1) <= 4 and abs(r.br - p2) <= 4:\n",
    "                            font_properties = \" \".join([font_properties, 'underlined'])\n",
    "\n",
    "                    style_counts.append(font_properties)\n",
    "    styles = dict(Counter(style_counts))\n",
    "\n",
    "    style_list = sorted(styles.items(), key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    return style_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2da473-3bc3-4aa1-bccc-858bf5b970f0",
   "metadata": {},
   "source": [
    "### New Methodology: get_opinion()\n",
    "There are typically 2-3 major headers in the court cases that I've seen. Usually titled Case Summary, Core Terms, or Opinion and so forth; they all have the same font properties such as size, flags, and font style. While Case Summary and Core Terms may or may not be present, it is apparent that Opinion will most likely be present (high propbability).\n",
    "\n",
    "So get_styles() will determine the font properties that are unique to the paragraph text. Using that, we can use the paragraph text size to our advantage (names: p_size).\n",
    "\n",
    "This function takes the document and reads the pdf line by line, each line having a 'count' tagged to it. So the first line read is 1, second is 2, and so forth. This will help with finding line location in the future. For each line read, the counter adds 1 and then moves on to splitting the line into spans. It compares the span text size to the paragraph text size. If the span text size is equal to or greater than the paragraph text size, the function will add it to the texts string. This gets just the text and removes and subscripts in each line.\n",
    "\n",
    "The function will then split texts into a list so that if the number of words in the line is between 0 and 10, the line will be considered a potential header (saved in headers dict with the value being the location).\n",
    "\n",
    "The main purpose of this function is to find out where the major header, Opinion, is located (assuring that the correct location has been most likely found). The variable is opinion_loc and will be used in the future. The extensive checks are put in place to reduce the probability of extracting the wrong location of the word \"Opinion\" (such as the word appearing more than once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe1b1f9a-823d-4979-b784-5cd7dac7d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opinion(doc, style_list):\n",
    "\n",
    "    headers = {}\n",
    "    count = 0\n",
    "    p_size = int(style_list[0][0].split('size')[1].split()[0].strip(','))\n",
    "\n",
    "    for page in doc:\n",
    "        #, flags=11\n",
    "        blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                texts = \"\"\n",
    "                count+=1\n",
    "                for s in l['spans']:\n",
    "                    if s['size'] >= p_size:\n",
    "                        texts = \"\".join ([texts, s['text']])\n",
    "                text_list = texts.split()\n",
    "                if len(text_list) > 0 and len(text_list) < 7:\n",
    "                    headers.update({texts:count})\n",
    "\n",
    "    opinion_loc = headers['Opinion']\n",
    "    return opinion_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5398ee-d0ba-4c78-b46f-272f681c838b",
   "metadata": {},
   "source": [
    "### Getting the Major Headers\n",
    "\n",
    "This code block can get the 2-3 major headers (Core Terms, Case Summary, Opinion, etc.). Currently, I have no use for this code, but for demonstrative purposes, I will keep it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6ae91b-d65e-4a4c-b32b-e39ebf51aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majors(doc, style_list, opinion_loc):\n",
    "    \n",
    "    count = 0\n",
    "    p_size = int(style_list[0][0].split('size')[1].split()[0].strip(','))\n",
    "    new_headers = {}\n",
    "    header_properties = \"\"\n",
    "\n",
    "    for page in doc:\n",
    "        #, flags=11\n",
    "        blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                count+=1\n",
    "                if count==opinion_loc:\n",
    "                    for s in l['spans']:\n",
    "                        header_properties = \"Font: '%s' (%s), size %g, color #%06x\" % (\n",
    "                            s[\"font\"],  # font name\n",
    "                            flags_decomposer(s[\"flags\"]),  # readable font flags\n",
    "                            s[\"size\"],  # font size\n",
    "                            s[\"color\"],  # font color\n",
    "                        )\n",
    "\n",
    "    count = 0                \n",
    "    for page in doc:\n",
    "        #, flags=11\n",
    "        blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                count+=1\n",
    "                for s in l['spans']:\n",
    "                    font_properties = \"Font: '%s' (%s), size %g, color #%06x\" % (\n",
    "                        s[\"font\"],  # font name\n",
    "                        flags_decomposer(s[\"flags\"]),  # readable font flags\n",
    "                        s[\"size\"],  # font size\n",
    "                        s[\"color\"],  # font color\n",
    "                    )\n",
    "                    if font_properties==header_properties:\n",
    "                        new_headers.update({s['text']:count})\n",
    "\n",
    "    return new_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7252ea10-063d-4a5d-b817-a217a9252166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Case Summary': 11, 'Opinion': 26}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open('pplvpv.pdf')\n",
    "style_list = get_styles(doc)\n",
    "opinion_loc = get_opinion(doc, style_list)\n",
    "get_majors(doc, style_list, opinion_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6cb85dd1-77a9-402a-b89c-4669d5fb5d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Core Terms': 11, 'LexisNexis® Headnotes': 15, 'Opinion': 119}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open('usvbell.pdf')\n",
    "style_list = get_styles(doc)\n",
    "opinion_loc = get_opinion(doc, style_list)\n",
    "get_majors(doc, style_list, opinion_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d225ec-c396-4f97-8044-04f7ddd9e7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Case Summary': 18, 'Opinion': 53}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open('statevward.pdf')\n",
    "style_list = get_styles(doc)\n",
    "opinion_loc = get_opinion(doc, style_list)\n",
    "get_majors(doc, style_list, opinion_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7dd86d-dd20-4959-bb4e-a6b6a28a2c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Core Terms': 11, 'Opinion': 18}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open('tompvus.pdf')\n",
    "style_list = get_styles(doc)\n",
    "opinion_loc = get_opinion(doc, style_list)\n",
    "get_majors(doc, style_list, opinion_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eab0fc-11eb-451e-aaf8-b083eade897a",
   "metadata": {},
   "source": [
    "### get_masterlist()\n",
    "Next step is to get a list of subheaders under the major header, Opinion. \n",
    "\n",
    "Beings with creating a masterlist of font style properties that define a subheader. \n",
    "\n",
    "vocab_font is the font for vocabulary words in text. This is where the text is bold, italicized, underlined, and matches the size of the paragraph text size. I don't include vocab where text size is smaller than paragraph text because that will be filtered out later. I don't include vocab where text size is larger than paragraph text because that would be considered a header/subheader.\n",
    "\n",
    "links_font is the font for words that are considered 'links'. This is where the text is blue and matches the size of the paragraph text size. I don't include links where text size is smaller than paragraph text because that will be filtered out later. I don't include links where text size is larger than paragraph text because that would be considered a header/subheader.\n",
    "\n",
    "I start creating a master list of subheader styles called slist. I filter out the fonts that match the paragraph font style, the links font style, and the vocab font style. I also filter out fonts where the size is smaller than the paragraph text size. \n",
    "\n",
    "This function returns a list of header/subheader fonts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d4d124-cb8f-46d6-8804-57a17fe80cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_master(style_list):\n",
    "\n",
    "    p_size = int(style_list[0][0].split('size')[1].split()[0].strip(','))\n",
    "    p_color = style_list[0][0].split('color')[1].split()[0].strip(',')\n",
    "    p_font = style_list[0][0]\n",
    "\n",
    "    bad_fonts = []\n",
    "\n",
    "    for style in style_list:\n",
    "        font_str = style[0]\n",
    "        s_size = int(font_str.split('size')[1].split()[0].strip(','))\n",
    "        s_color = font_str.split('color')[1].split()[0].strip(',')\n",
    "\n",
    "        # if font matches paragraph font, it's a bad_font\n",
    "        if font_str==p_font:\n",
    "            bad_fonts+=[font_str]\n",
    "        # if font doesn't match paragraph text color, it's a bad_font\n",
    "        if s_color!=p_color:\n",
    "            bad_fonts+=[font_str]\n",
    "        # if font matches characteristics of vocab word font, it's a bad font\n",
    "        if ('bold' in font_str and 'underlined' in font_str) and ('italic' in font_str and p_size==s_size):\n",
    "            bad_fonts+=[font_str]\n",
    "        # if font size is smaller than paragraph text size, it's a bad_font\n",
    "        if s_size<p_size:\n",
    "            bad_fonts+=[font_str]\n",
    "\n",
    "    master = []\n",
    "    for style in style_list:\n",
    "        if style[0] not in bad_fonts:\n",
    "            master += [style[0]]\n",
    "\n",
    "    return master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be02dbec-2fb5-4d0a-931d-928fd36be8e9",
   "metadata": {},
   "source": [
    "### get_subheaders()\n",
    "This function will read the pdf, starting from opinion_loc, and compare each span font style to the mastserlist. If the font style matches a font in the masterlist, add the line to opinion_subheaders list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d198009-9d7f-4ebe-9901-224aaa618a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subheaders(doc, style_list, opinion_loc, master):\n",
    "\n",
    "    for page in doc:\n",
    "\n",
    "        paths = page.get_drawings()  # get drawings on the page\n",
    "\n",
    "        drawn_lines = []\n",
    "        for p in paths:\n",
    "            # print(p)\n",
    "            for item in p[\"items\"]:\n",
    "                # print(item[0])\n",
    "                if item[0] == \"l\":  # an actual line\n",
    "                    # print(item[1], item[2])\n",
    "                    p1, p2 = item[1], item[2]\n",
    "                    if p1.y == p2.y:\n",
    "                        drawn_lines.append((p1, p2))\n",
    "                elif item[0] == \"re\":  # a rectangle: check if height is small\n",
    "                    # print(item[0])\n",
    "                    # print(item[1])\n",
    "                    r = item[1]\n",
    "                    if r.width > r.height and r.height <= 2:\n",
    "                        drawn_lines.append((r.tl, r.tr))  # take top left / right points\n",
    "\n",
    "    count = 0\n",
    "    opinion_subheaders = {}\n",
    "    p_color = style_list[0][0].split('color')[1].split()[0].strip(',')\n",
    "\n",
    "    for page in doc:\n",
    "        #, flags=11\n",
    "        blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                texts = \"\"\n",
    "                count+=1\n",
    "                span_fonts = []\n",
    "                if count>=opinion_loc:\n",
    "                    for s in l['spans']:\n",
    "                        font_properties = \"Font: '%s' (%s), size %g, color #%06x\" % (\n",
    "                            s[\"font\"],  # font name\n",
    "                            flags_decomposer(s[\"flags\"]),  # readable font flags\n",
    "                            s[\"size\"],  # font size\n",
    "                            s[\"color\"],  # font color\n",
    "                        )\n",
    "\n",
    "                        r = fitz.Rect(s['bbox']) \n",
    "                        for p1, p2 in drawn_lines:  # check distances for start / end points\n",
    "                            if abs(r.bl - p1) <= 4 and abs(r.br - p2) <= 4:\n",
    "                                font_properties = \" \".join([font_properties, 'underlined'])\n",
    "                    \n",
    "                        span_fonts+=[font_properties]\n",
    "                        texts = \"\".join ([texts, s['text']])\n",
    "                \n",
    "                text_list = texts.split()\n",
    "                if len(text_list) > 0 and len(text_list) < 7:\n",
    "                    if any(i in span_fonts for i in master):\n",
    "                        opinion_subheaders.update({texts:count})\n",
    "                    if texts.isupper()==True:\n",
    "                        opinion_subheaders.update({texts:count})\n",
    "                    \n",
    "    return opinion_subheaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0dbd1879-8b71-43ef-ac05-04920f439157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_links_headers(doc, style_list, opinion_subheaders):\n",
    "    p_color = style_list[0][0].split('color')[1].split()[0].strip(',')\n",
    "    p_size = int(style_list[0][0].split('size')[1].split()[0].strip(','))\n",
    "    # list of potential headers\n",
    "    keys_as_list = list(opinion_subheaders)\n",
    "    # keeping track of the number of links in each section\n",
    "    link_tracker = {}\n",
    "    zero_links = {}\n",
    "\n",
    "    for header_index in range(len(keys_as_list)):\n",
    "        start = keys_as_list[header_index]\n",
    "        start_span = opinion_subheaders[start]\n",
    "        \n",
    "        if header_index+1 < len(keys_as_list):\n",
    "            end = keys_as_list[header_index+1]\n",
    "            end_span = opinion_subheaders[end]\n",
    "        else:\n",
    "            end = keys_as_list[header_index]\n",
    "            end_span = opinion_subheaders[end]\n",
    "\n",
    "        # keeping track of the number of links found in each potential header section\n",
    "        links_counter = 0\n",
    "        count = 0\n",
    "\n",
    "        for page in doc:\n",
    "\n",
    "            paths = page.get_drawings()  # get drawings on the page\n",
    "\n",
    "            drawn_lines = []\n",
    "            for p in paths:\n",
    "                # print(p)\n",
    "                for item in p[\"items\"]:\n",
    "                    # print(item[0])\n",
    "                    if item[0] == \"l\":  # an actual line\n",
    "                        # print(item[1], item[2])\n",
    "                        p1, p2 = item[1], item[2]\n",
    "                        if p1.y == p2.y:\n",
    "                            drawn_lines.append((p1, p2))\n",
    "                    elif item[0] == \"re\":  # a rectangle: check if height is small\n",
    "                        # print(item[0])\n",
    "                        # print(item[1])\n",
    "                        r = item[1]\n",
    "                        if r.width > r.height and r.height <= 2:\n",
    "                            drawn_lines.append((r.tl, r.tr))  # take top left / right points\n",
    "            \n",
    "            blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "\n",
    "            for b in blocks:  # iterate through the text blocks\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        # keeping track of span index\n",
    "                        count += 1\n",
    "\n",
    "                        font_properties = \"Font: '%s' (%s), size %g, color #%06x\" % (\n",
    "                            s[\"font\"],  # font name\n",
    "                            flags_decomposer(s[\"flags\"]),  # readable font flags\n",
    "                            s[\"size\"],  # font size\n",
    "                            s[\"color\"],  # font color\n",
    "                        )\n",
    "\n",
    "                        r = fitz.Rect(s['bbox']) \n",
    "                        for p1, p2 in drawn_lines:  # check distances for start / end points\n",
    "                            if abs(r.bl - p1) <= 4 and abs(r.br - p2) <= 4:\n",
    "                                font_properties = \" \".join([font_properties, 'underlined'])\n",
    "                        \n",
    "                        # checking text in between start and end index\n",
    "                        if count >= start_span and count < end_span:\n",
    "                            # seting up check indicator for if span is a link or not\n",
    "                            # assuming text is a link\n",
    "                            check = True\n",
    "                            # if it's the same color as the paragraph text\n",
    "                            if s['color']!=p_color and s['size']==p_size:\n",
    "                                links_counter+=1\n",
    "\n",
    "        link_tracker.update({start:{'counter':links_counter, 'location':opinion_subheaders[start]}})\n",
    "\n",
    "    links_as_list = list(link_tracker)\n",
    "    for each_counter in range(len(link_tracker)):\n",
    "        current_header = links_as_list[each_counter]\n",
    "        if link_tracker[current_header]['counter']==0:\n",
    "            zero_links.update({current_header:link_tracker[current_header]['location']})\n",
    "    \n",
    "    return zero_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "54f429a2-5356-44e7-bee7-6519ed665a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Opinion': 26,\n",
       " ' [**498]  [*345] Toko Serita, J.': 27,\n",
       " ' [**499] Relevant Laws': 45,\n",
       " '(CPL 440.10 [6]).': 98,\n",
       " ' [**501]  [*350] 1. Findings of Fact': 141,\n",
       " ' [*351] 2. Conclusions of Law': 172,\n",
       " 'from a young [****5]  age.17': 202,\n",
       " ' [***20] ': 365}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open('pplvpv.pdf')\n",
    "style_list = get_styles(doc)\n",
    "opinion_loc = get_opinion(doc, style_list)\n",
    "master = get_master(style_list)\n",
    "get_subheaders(doc, style_list, opinion_loc, master)\n",
    "# get_zero_links_headers(doc, style_list, opinion_subheaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "14ab3fae-8d3b-474d-99f0-46e8fa7f4d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Opinion': 49,\n",
       " '¶1  [*759]  [**887] FEARING, J. —': 50,\n",
       " '[S]ex traffickers select victims who demonstrate ': 51,\n",
       " 'vulnerabilities including homelessness, substance ': 52,\n",
       " '[T]raffickers control their victims through physical ': 60,\n",
       " 'violence, sexual violence, psychological violence ': 61,\n",
       " 'socially isolating them, and controlling them ': 67,\n",
       " 'drug dependency. …': 69,\n",
       " 'prostitution [*760] . Because overwhelming evidence ': 84,\n",
       " 'FACTS': 92,\n",
       " \"behind RCW 9A.40.100, Washington's trafficking \": 111,\n",
       " ' [*762] ': 165,\n",
       " ' [**889] ': 212,\n",
       " 'Jane [***9]  ': 259,\n",
       " ' [*765] ': 306,\n",
       " ' [**890] ': 314,\n",
       " ' [**892] ': 499,\n",
       " ' [**893]  ': 604,\n",
       " 'son [***21]  to view her naked.': 607,\n",
       " 'PROCEDURE': 664,\n",
       " 'Washington [***24]  ': 690,\n",
       " 'trafficking.': 728,\n",
       " 'Uncertainty. [***26] ': 756,\n",
       " 'trafficking and second degree promoting prostitution.': 783,\n",
       " 'could [***30]  say no.': 870,\n",
       " 'trafficking described by [Jane].': 900,\n",
       " '3.1.1.4. The defendant exerted psychological ': 905,\n",
       " \"harm, restrain, or destroy [Jane]'s property\": 910,\n",
       " ' [*779] ': 934,\n",
       " 'LAW AND ANALYSIS': 946,\n",
       " 'Human Trafficking': 954,\n",
       " \"9A.40.100, Washington's human trafficking statute, \": 957,\n",
       " ' [**897] ': 976,\n",
       " 'fastest growing worldwide criminal industry. Human ': 981,\n",
       " '(July [*780]  ': 983,\n",
       " 'TRAFFICKING: A GLOBAL PERSPECTIVE 2 (2010).': 988,\n",
       " 'Marjorie A. Shields, Annotation, Validity, Construction, ': 1002,\n",
       " 'trafficking. ': 1019,\n",
       " 'BRIAN ': 1020,\n",
       " 'BONLENDER, ': 1021,\n",
       " 'WASHINGTON DEPARTMENT OF COMMERCE, STATEWIDE ': 1022,\n",
       " 'COORDINATING COMMITTEE ON SEX TRAFFICKING: REPORT ': 1023,\n",
       " 'TRAFFICKING ': 1025,\n",
       " '(RCW ': 1026,\n",
       " 'RCW 9.94A.835.': 1069,\n",
       " 'victim to engage in commercial sex.': 1073,\n",
       " 'Force': 1089,\n",
       " 'of human trafficking. Trafficking comprises the ': 1141,\n",
       " 'generally combine to effectuate sexual trafficking. ': 1150,\n",
       " ' [**899] ': 1172,\n",
       " 'federal human trafficking statute, because Bell ': 1274,\n",
       " 'sex acts for Bell.': 1277,\n",
       " '2017), McKenzie Carson trafficked a seventeen-year-': 1279,\n",
       " 'Coercion': 1372,\n",
       " '(b), or (c).': 1392,\n",
       " 'Fraud': 1473,\n",
       " 'Causation': 1526,\n",
       " ' [*792] ': 1541,\n",
       " 'seeking favors. [***51] ': 1559,\n",
       " 'results [***52]  ': 1584,\n",
       " '“‘I ': 1627,\n",
       " 'Vagueness': 1673,\n",
       " 'directly [***55]  or indirectly the intent:': 1704,\n",
       " 'prostitution. [***56] ': 1739,\n",
       " ' [*796] ': 1740,\n",
       " ' [**905] ': 1793,\n",
       " 'decisions [***59]  ': 1842,\n",
       " ' [*799]  CONCLUSION [***60] ': 1891,\n",
       " 'References': 1897}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open('statevbraun.pdf')\n",
    "style_list = get_styles(doc)\n",
    "opinion_loc = get_opinion(doc, style_list)\n",
    "master = get_master(style_list)\n",
    "get_subheaders(doc, style_list, opinion_loc, master)\n",
    "# get_zero_links_headers(doc, style_list, opinion_subheaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68b5ec57-51fc-42d0-86f0-2b29373fb3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Opinion': 53,\n",
       " 'OPINION': 67,\n",
       " 'Facts and Procedural History': 68,\n",
       " 'Analysis': 238,\n",
       " 'I. Sufficiency': 248,\n",
       " '301(3)(A), (C), (D).': 347,\n",
       " 'B. Promoting Prostitution': 382,\n",
       " 'II. Failure to Merge Convictions': 411,\n",
       " 'sex ': 624,\n",
       " 'convictions [*16]  ': 439,\n",
       " 'prong of the Blockburger analysis.': 496,\n",
       " 'Id. ': 509,\n",
       " '39-13-301(3)(A), (C), (D).': 581,\n",
       " \"defendant's [*21]  \": 628,\n",
       " 'III. Jury Instruction': 630,\n",
       " 'evidence [*23]  ': 692,\n",
       " 'accomplice\\'s] testimony.\" Id.': 730,\n",
       " 'Conclusion': 758,\n",
       " 'J. ROSS DYER, JUDGE': 765}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open('statevward.pdf')\n",
    "style_list = get_styles(doc)\n",
    "opinion_loc = get_opinion(doc, style_list)\n",
    "master = get_master(style_list)\n",
    "get_subheaders(doc, style_list, opinion_loc, master)\n",
    "# get_zero_links_headers(doc, style_list, opinion_subheaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d8a0b7c-6cf6-44e4-bfe8-5a41a900cd83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Opinion': 18,\n",
       " 'DECISION AND ORDER': 19,\n",
       " 'See Second Circuit Docket No. 17-822.': 23,\n",
       " 'SO ORDERED.': 54,\n",
       " '/s/ Richard J. Arcara': 57,\n",
       " 'HONORABLE RICHARD J. ARCARA': 58,\n",
       " 'UNITED STATES DISTRICT JUDGE': 59}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open('tompvus.pdf')\n",
    "style_list = get_styles(doc)\n",
    "opinion_loc = get_opinion(doc, style_list)\n",
    "master = get_master(style_list)\n",
    "get_subheaders(doc, style_list, opinion_loc, master)\n",
    "# get_zero_links_headers(doc, style_list, opinion_subheaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b5d3fb76-0575-4bef-98f6-19eaa20078b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "293c0339-d0ba-40fe-9429-2ab2f5d4568b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Opinion': 119,\n",
       " 'ORDER': 120,\n",
       " 'I. FACTUAL BACKGROUND': 125,\n",
       " 'II. PROCEDURAL BACKGROUND': 139,\n",
       " 'III. DISCUSSION': 181,\n",
       " 'A. Motion for Judgment of Acquittal': 182,\n",
       " 'HN1[': 184,\n",
       " '2. Summary of the Evidence': 213,\n",
       " '700, [*40]  745, 804.': 617,\n",
       " 'a. Counts 1 through 3': 618,\n",
       " 'HN2[': 622,\n",
       " 'HN3[': 631,\n",
       " 'b. Counts 4 through 7': 746,\n",
       " 'HN4[': 747,\n",
       " 'B. Motion for New Trial': 781,\n",
       " 'HN5[': 785,\n",
       " '2. Evidence Presented at Trial': 799,\n",
       " \"3. Addition of T.A.'s Testimony\": 816,\n",
       " 'a. Newly Discovered Evidence': 833,\n",
       " 'HN7[': 834,\n",
       " 'b. Due Diligence': 854,\n",
       " 'HN8[': 855,\n",
       " 'c. Cumulative or Impeaching': 875,\n",
       " 'HN9[': 878,\n",
       " 'd. Materiality': 899,\n",
       " 'e. Likelihood of Acquittal': 903,\n",
       " 'HN10[': 904,\n",
       " 'IV. CONCLUSION': 926,\n",
       " 'IT IS SO ORDERED.': 929,\n",
       " 'U.S. DISTRICT JUDGE': 933}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open('usvbell.pdf')\n",
    "style_list = get_styles(doc)\n",
    "opinion_loc = get_opinion(doc, style_list)\n",
    "master = get_master(style_list)\n",
    "get_subheaders(doc, style_list, opinion_loc, master)\n",
    "# get_zero_links_headers(doc, style_list, opinion_subheaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad55a5-4d80-47c4-8223-277604c2d595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
