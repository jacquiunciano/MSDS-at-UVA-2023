{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89dfbf7f-f4f4-43bd-85c7-746c5b7b42eb",
   "metadata": {},
   "source": [
    "**Relevent Source Materials**\n",
    "\n",
    "https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n",
    "\n",
    "ETA Module 6, Vectorization with SciKit Learn\n",
    "\n",
    "Stat. Learning Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a131cf2-3f81-42b9-b640-d5a56631ba58",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43a1eba-f3c0-450a-9b67-9aba87d8f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e1ef3-9ca9-447e-a2ae-5af7026616ef",
   "metadata": {},
   "source": [
    "### SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7358c32c-f4e0-48a1-8a6a-3481196801f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A.B. v. Shilo Inn, Salem, LLC, 2023 U.S. Dist. LEXIS 143289</th>\n",
       "      <td>C:/Users/jacqu/Downloads/Court Case PDFs/Court...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.D. v. Best Western Int_l, Inc., 2023 U.S. Dist. LEXIS 150376</th>\n",
       "      <td>C:/Users/jacqu/Downloads/Court Case PDFs/Court...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.D. v. Choice Hotels Int_l, Inc., 2023 U.S. Dist. LEXIS 150380</th>\n",
       "      <td>C:/Users/jacqu/Downloads/Court Case PDFs/Court...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.M. v. Wyndham Hotels</th>\n",
       "      <td>C:/Users/jacqu/Downloads/Court Case PDFs/Court...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bacon v. Marshall, 2023 U.S. App. LEXIS 32309</th>\n",
       "      <td>C:/Users/jacqu/Downloads/Court Case PDFs/Court...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             txt_path\n",
       "file_title                                                                                           \n",
       "A.B. v. Shilo Inn, Salem, LLC, 2023 U.S. Dist. ...  C:/Users/jacqu/Downloads/Court Case PDFs/Court...\n",
       "A.D. v. Best Western Int_l, Inc., 2023 U.S. Dis...  C:/Users/jacqu/Downloads/Court Case PDFs/Court...\n",
       "A.D. v. Choice Hotels Int_l, Inc., 2023 U.S. Di...  C:/Users/jacqu/Downloads/Court Case PDFs/Court...\n",
       "B.M. v. Wyndham Hotels                              C:/Users/jacqu/Downloads/Court Case PDFs/Court...\n",
       "Bacon v. Marshall, 2023 U.S. App. LEXIS 32309       C:/Users/jacqu/Downloads/Court Case PDFs/Court..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MODIFY THIS\n",
    "# get path to your folder that holds the txt files\n",
    "source_files = \"C:/Users/jacqu/Downloads/Court Case PDFs/Court Case TXTs\"\n",
    "# outputs a list of all the txt files in the folder\n",
    "source_file_list = sorted(glob(f\"{source_files}/*.txt\"))\n",
    "\n",
    "# creates a list of tuples with an elememt for the source path and\n",
    "# for the file title\n",
    "file_data = []\n",
    "for source_file_path in source_file_list:\n",
    "    # split might be different, recommend checking with INFO.sample() or .head()\n",
    "    file_title = source_file_path.split('\\\\')[-1].split(\".txt\")[0]\n",
    "    file_data.append((source_file_path, file_title))\n",
    "\n",
    "# creating df with the file title as the index and source path as a col\n",
    "INFO = pd.DataFrame(file_data, columns=['txt_path','file_title'])\\\n",
    "    .set_index('file_title').sort_index()\n",
    "INFO.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe67e024-bc7b-45b6-b7f7-b96f096dac77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A.B. v. Shilo Inn, Salem, LLC, 2023 U.S. Dist. LEXIS 143289</th>\n",
       "      <td>OPINION AND ORDER GRANTING DEFENDANT  SUMMIT H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.D. v. Best Western Int_l, Inc., 2023 U.S. Dist. LEXIS 150376</th>\n",
       "      <td>OPINION AND ORDER This matter comes before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.D. v. Choice Hotels Int_l, Inc., 2023 U.S. Dist. LEXIS 150380</th>\n",
       "      <td>OPINION AND ORDER This matter comes before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.M. v. Wyndham Hotels</th>\n",
       "      <td>ORDER GRANTING IN PART AND DENYING IN  PART DE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bacon v. Marshall, 2023 U.S. App. LEXIS 32309</th>\n",
       "      <td>[*1] ORDER AND JUDGMENT* _____________________...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            narrative\n",
       "title                                                                                                \n",
       "A.B. v. Shilo Inn, Salem, LLC, 2023 U.S. Dist. ...  OPINION AND ORDER GRANTING DEFENDANT  SUMMIT H...\n",
       "A.D. v. Best Western Int_l, Inc., 2023 U.S. Dis...  OPINION AND ORDER This matter comes before the...\n",
       "A.D. v. Choice Hotels Int_l, Inc., 2023 U.S. Di...  OPINION AND ORDER This matter comes before the...\n",
       "B.M. v. Wyndham Hotels                              ORDER GRANTING IN PART AND DENYING IN  PART DE...\n",
       "Bacon v. Marshall, 2023 U.S. App. LEXIS 32309       [*1] ORDER AND JUDGMENT* _____________________..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making the CORPUS\n",
    "## CORPUS df: multindex = doc name/index, sent. num, token num\n",
    "## columns = pos tag, token str, term str (token str normalized)\n",
    "\n",
    "narratives_list = []\n",
    "for doc_idx, txt_path in enumerate(INFO['txt_path']):\n",
    "    with open(txt_path, 'r',  encoding='utf-8') as file:\n",
    "        narrative = file.read()\n",
    "    narratives_list.append({\"title\": INFO.index[doc_idx], \"narrative\": narrative})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "narratives = pd.DataFrame(narratives_list)\n",
    "narratives = narratives.reset_index().set_index(\"title\")\n",
    "narratives = narratives.drop(columns=['index'])\n",
    "narratives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c8b807-8801-4387-9ffd-5056a272589d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A.B. v. Shilo Inn, Salem, LLC, 2023 U.S. Dist. LEXIS 143289</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(OPINION, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(AND, CC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ORDER, NNP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(GRANTING, NNP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(DEFENDANT, NNP)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              token_pos\n",
       "title                                              sent_num token_num                  \n",
       "A.B. v. Shilo Inn, Salem, LLC, 2023 U.S. Dist. ... 0        0             (OPINION, NN)\n",
       "                                                            1                 (AND, CC)\n",
       "                                                            2              (ORDER, NNP)\n",
       "                                                            3           (GRANTING, NNP)\n",
       "                                                            4          (DEFENDANT, NNP)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(index=narratives.index)\n",
    "df['sent_str'] = [nltk.sent_tokenize(narratives.narrative[x]) for x in range(len(narratives))]\n",
    "df = df.explode('sent_str')\n",
    "s1 = df.index.to_series()\n",
    "s2 = s1.groupby(s1).cumcount()\n",
    "df.index = [df.index, s2]\n",
    "df.index.names = ['title','sent_num']\n",
    "# nltk.word_tokenize(df.sent_str[x])\n",
    "df['token_pos'] = [nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(df.sent_str[x])) for x in range(len(df))]\n",
    "df = df.explode('token_pos')\n",
    "s1 = df.index.to_series()\n",
    "s2 = s1.groupby(s1).cumcount()\n",
    "df.index = [df.index.get_level_values(level=0), df.index.get_level_values(level=1), s2]\n",
    "df.index.names = ['title','sent_num', 'token_num']\n",
    "df.drop(columns=['sent_str'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c17063-eaee-4bad-b6f9-eca5e9739bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A.B. v. Shilo Inn, Salem, LLC, 2023 U.S. Dist. LEXIS 143289</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>OPINION</td>\n",
       "      <td>opinion</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AND</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORDER</td>\n",
       "      <td>order</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRANTING</td>\n",
       "      <td>granting</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEFENDANT</td>\n",
       "      <td>defendant</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       token_str  \\\n",
       "title                                              sent_num token_num              \n",
       "A.B. v. Shilo Inn, Salem, LLC, 2023 U.S. Dist. ... 0        0            OPINION   \n",
       "                                                            1                AND   \n",
       "                                                            2              ORDER   \n",
       "                                                            3           GRANTING   \n",
       "                                                            4          DEFENDANT   \n",
       "\n",
       "                                                                        term_str  \\\n",
       "title                                              sent_num token_num              \n",
       "A.B. v. Shilo Inn, Salem, LLC, 2023 U.S. Dist. ... 0        0            opinion   \n",
       "                                                            1                and   \n",
       "                                                            2              order   \n",
       "                                                            3           granting   \n",
       "                                                            4          defendant   \n",
       "\n",
       "                                                                      pos_tag  \n",
       "title                                              sent_num token_num          \n",
       "A.B. v. Shilo Inn, Salem, LLC, 2023 U.S. Dist. ... 0        0              NN  \n",
       "                                                            1              CC  \n",
       "                                                            2             NNP  \n",
       "                                                            3             NNP  \n",
       "                                                            4             NNP  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_str'] = df.token_pos.apply(lambda x: x[0].strip())\n",
    "df['term_str'] = df.token_pos.apply(lambda x: x[0].lower().strip())\n",
    "df['pos_tag'] = df.token_pos.apply(lambda x: x[1])\n",
    "CORPUS = df.drop(columns=\"token_pos\")\n",
    "CORPUS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61bba8f7-5689-47be-96cf-b1ceb17e9692",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3418)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7325d0-9401-4168-83a5-6da64b355a27",
   "metadata": {},
   "source": [
    "**Here's a question:** Do we want to get rid of stop words? Maybe use a custom list of stop words... and do we want to do lemmatization on the words? Consult Brain??? 0.0 \n",
    "\n",
    "If the answer is no to one or both questions, we can just have a df with index: title and columns: raw_narrative, n_tokens and go straight to TFIDFVec. We don't need to do most of the steps above; just go straight from narratives df to tfidf_engine.fit_transform(narratives.narrative). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4eb8a-6efe-4c59-b908-41fe46625d71",
   "metadata": {},
   "source": [
    "### Vectorization with SciKit Learn, TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad88c2-6878-462c-b9d5-0c5d83e6480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DOC df: index = doc name/index\n",
    "## columns = narrative str, num tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26bf91-e9f4-47a7-b852-0d58b2bbb1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_docs(CORPUS, ohco_level, term_col='term_str'):\n",
    "    OHCO = CORPUS.index.names\n",
    "    CORPUS[term_col] = CORPUS[term_col].astype('str')\n",
    "    DOC = CORPUS.groupby(OHCO[:ohco_level])[term_col].apply(lambda x:' '.join(x)).to_frame('doc_str')\n",
    "    return DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3dcc9-ff12-41bf-8b05-d53accdb16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC = gather_docs(CORPUS, 1)\n",
    "DOC['n_tokens'] = DOC.doc_str.apply(lambda x: len(x.split()))\n",
    "DOC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716946b-87f5-4baa-8695-40d26030a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (2,2)\n",
    "n_terms = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea9a40-b661-4190-99ad-ba766fd8cc92",
   "metadata": {},
   "source": [
    "**Applying TFIDF Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55afd92-58a2-4c84-bd77-b55dadc764d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_engine = TfidfVectorizer(\n",
    "    stop_words = 'english',\n",
    "    ngram_range = ngram_range,\n",
    "    max_features = n_terms,\n",
    "    norm = 'l2', \n",
    "    use_idf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a0b8c-34b9-4911-b972-e706623e9a0c",
   "metadata": {},
   "source": [
    "**Vectorized data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55e407-e08b-49dc-8bd5-939f9fa41813",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_engine.fit_transform(DOC.doc_str)\n",
    "print(X[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c02a6b3-b93b-4da7-8df3-e1494eb0fd3a",
   "metadata": {},
   "source": [
    "**Learned vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6cb83-1bae-44a0-94a3-78b81224edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "print(dict(itertools.islice(tfidf_engine.vocabulary_.items(), 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab35ca-8667-4b18-9909-a58823b4e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF = pd.DataFrame(X.toarray(), columns=tfidf_engine.get_feature_names_out(), index=DOC.index)\n",
    "TFIDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e097d-8e30-4001-ae7b-5222513a0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF.stack().to_frame('score').score.nlargest(20).to_frame('score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f7108-9e63-4a82-9601-7ab309ad60e0",
   "metadata": {},
   "source": [
    "### VOCAB DF\n",
    "Making a vocabulary list with significant uni/bi grams based on tfidf... these are weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4ec82-a3b6-44d5-952a-52dde13dc1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = TFIDF.mean().to_frame('tfidf_mean')\n",
    "VOCAB.sort_values('tfidf_mean', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10f875fd-910f-4e39-9d5e-4ad61b8c3fdc",
   "metadata": {},
   "source": [
    "VOCAB['df'] = TFIDF[TFIDF > 0].count()\n",
    "VOCAB['dfidf'] = VOCAB.df * np.log2(len(TFIDF)/VOCAB.df)\n",
    "VOCAB.sort_values('dfidf', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb21823a-6356-45db-94bb-79514e717aad",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad2c4f44-c246-4aec-8c4c-32e7039d9194",
   "metadata": {},
   "source": [
    "# Classifier - Algorithm - Logistic Reg.\n",
    "# fit the training dataset on the classifier, L2 penalty\n",
    "LR = LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "LR.fit(X,Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_LR = LR.predict(test_X)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"LR Accuracy Score -> \", accuracy_score(predictions_LR, test_Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4de51-929c-4217-ad0c-23ca4c035b56",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49597491-2c9c-4c61-bd5d-b9ce8b172a82",
   "metadata": {},
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X,Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(test_X)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, test_Y)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
